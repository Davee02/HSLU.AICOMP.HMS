{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PREPARATION_VOTE_METHOD = \"max_vote_window\" # \"max_vote_window\" or \"sum_and_normalize\". Decides how to aggregate the predictions of the overlapping windows\n",
    "PRETRAINED_MODEL_NAME_OR_PATH = \"inception_v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e1b745f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/aicomp/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/david/miniconda3/envs/aicomp/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "2025-12-03 16:57:28,612 :: root :: INFO :: Initialising Utils\n",
      "2025-12-03 16:57:29,126 :: root :: INFO :: Initialising Models\n",
      "2025-12-03 16:57:30,447 :: root :: INFO :: Initialising Datasets\n",
      "2025-12-03 16:57:30,607 :: root :: INFO :: Initialising Transformations\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm \n",
    "import wandb\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "\n",
    "if bool(os.environ.get(\"KAGGLE_URL_BASE\", \"\")):\n",
    "  import sys\n",
    "  # running on kaggle\n",
    "  sys.path.insert(0, \"/kaggle/input/hsm-source-files\")\n",
    "else:\n",
    "  # running locally\n",
    "  sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"..\")))\n",
    "\n",
    "from src.datasets.multi_spectrogram import MultiSpectrogramDataset\n",
    "from src.utils.k_folds_creator import KFoldCreator\n",
    "from src.utils.utils import get_models_save_path, set_seeds, get_raw_data_dir, get_processed_data_dir\n",
    "from src.models.base_cnn import BaseCNN\n",
    "from src.utils.constants import Constants \n",
    "from src.datasets.eeg_processor import EEGDataProcessor\n",
    "from src.transforms.mixup import MixUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2069d2a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidhodel\u001b[0m (\u001b[33mhms-hslu-aicomp-hs25\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59de120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 42\n",
    "    n_splits = 5\n",
    "    data_path = get_raw_data_dir()\n",
    "    train_eeg_spec_path = get_processed_data_dir() / \"eeg_spectrograms\" / \"train\" / \"cwt\"\n",
    "    \n",
    "    model_name = PRETRAINED_MODEL_NAME_OR_PATH\n",
    "    target_size = 6 \n",
    "    image_alignment = \"stacked\" # \"stacked\" or \"paired\"\n",
    "    \n",
    "    batch_size = 32\n",
    "    num_workers = 8\n",
    "    \n",
    "    # Stage-specific settings\n",
    "    stage1_epochs = 5\n",
    "    stage1_lr = 1e-3\n",
    "    \n",
    "    stage2_epochs = 3\n",
    "    stage2_lr = 5e-4\n",
    "    \n",
    "    patience = 5\n",
    "    min_delta = 0.001\n",
    "    \n",
    "    dropout_p = 0.1\n",
    "    \n",
    "    img_size = (128, 256)\n",
    "    # augmentations = [\"gaussian_noise\", \"time_reversal\", \"time_masking\", \"frequency_masking\"]\n",
    "    augmentations = []\n",
    "    mixup_alpha = 0.5\n",
    "    mixup_prob = 1.0\n",
    "\n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd182e4d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor initialized.\n",
      "Raw data path: '/home/david/git/aicomp/data'\n",
      "Processed data path: '/home/david/git/aicomp/data/processed'\n"
     ]
    }
   ],
   "source": [
    "TARGETS = Constants.TARGETS\n",
    "\n",
    "processor = EEGDataProcessor(raw_data_path=CFG.data_path, processed_data_path=get_processed_data_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd91183c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(train_df, valid_df):\n",
    "    \"\"\"\n",
    "    Updated to handle empty DataFrames safely.\n",
    "    Returns None for the loader if the input DataFrame is empty.\n",
    "    \"\"\"\n",
    "    train_loader = None\n",
    "    valid_loader = None\n",
    "    \n",
    "    if train_df is not None and not train_df.empty:\n",
    "        train_dataset = MultiSpectrogramDataset(\n",
    "            train_df, TARGETS, CFG.data_path, CFG.img_size, CFG.train_eeg_spec_path, mode='train', apply_augmentations=CFG.augmentations\n",
    "        )\n",
    "\n",
    "        # Create custom collate function for training if MixUp is enabled\n",
    "        train_collate_fn = MixUp(alpha=CFG.mixup_alpha, prob=CFG.mixup_prob) if CFG.mixup_prob > 0.0 else None\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=CFG.num_workers,\n",
    "            pin_memory=False,\n",
    "            drop_last=True,\n",
    "            persistent_workers=True,\n",
    "            collate_fn=train_collate_fn\n",
    "        )\n",
    "    \n",
    "    if valid_df is not None and not valid_df.empty:\n",
    "        valid_dataset = MultiSpectrogramDataset(\n",
    "            valid_df, TARGETS, CFG.data_path, CFG.img_size, CFG.train_eeg_spec_path, mode='train', apply_augmentations=[]\n",
    "        )\n",
    "        \n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=CFG.num_workers,\n",
    "            pin_memory=False,\n",
    "            drop_last=False,\n",
    "            persistent_workers=True\n",
    "        )\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ba7f18",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_one_stage(fold, stage_name, train_df, valid_df, group_name, data_preparation_vote_method, starting_checkpoint=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
    "    \n",
    "    if stage_name == \"stage1\":\n",
    "        lr = CFG.stage1_lr\n",
    "        epochs = CFG.stage1_epochs\n",
    "    else:\n",
    "        lr = CFG.stage2_lr\n",
    "        epochs = CFG.stage2_epochs\n",
    "    \n",
    "    print(f\"\\n--- Starting {stage_name} | Fold {fold} ---\")\n",
    "    \n",
    "    experiment_name = f\"{group_name}_{stage_name}_fold{fold}\"\n",
    "    \n",
    "    config = {\n",
    "        # Model\n",
    "        \"architecture\": CFG.model_name,\n",
    "        \"pretrained\": True,\n",
    "        \"image_alignment\": CFG.image_alignment,\n",
    "        # Data\n",
    "        \"fold\": fold,\n",
    "        \"stage\": stage_name,\n",
    "        \"features\": \"multi_spectrograms\",\n",
    "        \"window_selection\": data_preparation_vote_method,\n",
    "        \"augmentations\": CFG.augmentations,\n",
    "        \"mixup_alpha\": CFG.mixup_alpha,\n",
    "        \"mixup_prob\": CFG.mixup_prob,\n",
    "        # Training\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"learning_rate\": lr,\n",
    "        \"batch_size\": CFG.batch_size,\n",
    "        \"epochs\": epochs,\n",
    "        \"seed\": CFG.seed,\n",
    "        \"scheduler\": \"CosineAnnealingLR\",\n",
    "        \"dropout_p\": CFG.dropout_p,\n",
    "    }\n",
    "\n",
    "    wandb_run = wandb.init(\n",
    "        project=\"hms-aicomp-cnn-multispec\",\n",
    "        name=experiment_name,\n",
    "        group=group_name,\n",
    "        job_type=stage_name,\n",
    "        tags=['two-stage', stage_name, f'fold{fold}'],\n",
    "        config=config,\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "    model = BaseCNN(CFG.model_name, pretrained=True, num_classes=CFG.target_size, dropout_p=CFG.dropout_p, image_alignment=CFG.image_alignment)\n",
    "    model.to(device)\n",
    "    \n",
    "    if starting_checkpoint:\n",
    "        print(f\"Loading weights from {starting_checkpoint}...\")\n",
    "        model.load_state_dict(torch.load(starting_checkpoint))\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "    \n",
    "    train_loader, valid_loader = get_dataloaders(train_df, valid_df)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = get_models_save_path() / \"multi_spec_cnn_two_stage\" / CFG.model_name / data_preparation_vote_method / f'{stage_name}_fold{fold}.pth'\n",
    "    best_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"  --- Epoch {epoch+1}/{epochs} ---\")\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"{stage_name} Training E{epoch+1}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast(device_type=device.type, dtype=torch.float16):\n",
    "                outputs = model(images)\n",
    "                log_probs = F.log_softmax(outputs, dim=1)\n",
    "                loss = loss_fn(log_probs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "            wandb.log({\"train/loss\": loss.item()})\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(valid_loader, desc=f\"{stage_name} Validation\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                with autocast(device_type=device.type, dtype=torch.float16):\n",
    "                    outputs = model(images)\n",
    "                    log_probs = F.log_softmax(outputs, dim=1)\n",
    "                    loss = loss_fn(log_probs, labels)\n",
    "\n",
    "                valid_loss += loss.item() * images.size(0)\n",
    "\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        \n",
    "        epoch_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"   Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Valid Loss = {valid_loss:.4f}, LR = {epoch_lr:.6f}\")\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train/epoch_loss\": train_loss,\n",
    "            \"val/loss\": valid_loss,\n",
    "            \"val/kl_div\": valid_loss,\n",
    "            \"train/epoch_lr\": epoch_lr\n",
    "        })\n",
    "\n",
    "        if valid_loss < best_val_loss - CFG.min_delta:\n",
    "            best_val_loss = valid_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"  New best model saved with validation loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= CFG.patience:\n",
    "            print(f\"  Early stopping at epoch {epoch+1}\")\n",
    "            \n",
    "        scheduler.step()\n",
    "\n",
    "    return best_model_path, best_val_loss, wandb_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d9c86d5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_two_stage_training(df, data_preparation_vote_method):\n",
    "    print(\"Total Votes Distribution (Head):\")\n",
    "    print(df['total_votes'].head())\n",
    "    \n",
    "    mask_low_votes = df['total_votes'] < 10\n",
    "    mask_high_votes = df['total_votes'] >= 10\n",
    "    \n",
    "    print(f\"Stage 1 Data (Low Votes < 10): {mask_low_votes.sum()} samples\")\n",
    "    print(f\"Stage 2 Data (High Votes >= 10): {mask_high_votes.sum()} samples\")\n",
    "    \n",
    "    group_name = f\"twostage_{CFG.model_name}_multispec_dropout_{CFG.dropout_p}_mixup_alpha_{CFG.mixup_alpha}\"\n",
    "    \n",
    "    all_oof_preds = []\n",
    "    all_oof_labels = []\n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"\\n{'='*20} Processing FOLD {fold} {'='*20}\")\n",
    "        \n",
    "        valid_idx = df['fold'] == fold\n",
    "        valid_df = df[valid_idx].reset_index(drop=True)\n",
    "        \n",
    "        valid_stage2_df = valid_df[valid_df['total_votes'] >= 10].reset_index(drop=True)\n",
    "\n",
    "        # Stage 1: Train on low-vote data\n",
    "        train_stage1 = df[(df['fold'] != fold) & mask_low_votes].reset_index(drop=True)\n",
    "        \n",
    "        stage1_path, _, _ = train_one_stage(\n",
    "            fold=fold,\n",
    "            stage_name=\"stage1\",\n",
    "            train_df=train_stage1,\n",
    "            valid_df=valid_df,\n",
    "            group_name=group_name,\n",
    "            data_preparation_vote_method=data_preparation_vote_method\n",
    "        )\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "        # Stage 2: Train on high-vote data, starting from Stage 1 checkpoint\n",
    "        train_stage2 = df[(df['fold'] != fold) & mask_high_votes].reset_index(drop=True)\n",
    "        \n",
    "        stage2_path, best_val_loss, wandb_stage2_run = train_one_stage(\n",
    "            fold=fold,\n",
    "            stage_name=\"stage2\",\n",
    "            train_df=train_stage2,\n",
    "            valid_df=valid_stage2_df,\n",
    "            starting_checkpoint=stage1_path,\n",
    "            group_name=group_name,\n",
    "            data_preparation_vote_method=data_preparation_vote_method\n",
    "        )\n",
    "        \n",
    "        fold_scores.append(best_val_loss)\n",
    "\n",
    "        # Generate OOF predictions using Stage 2 model\n",
    "        print(f\"   --- Generating OOF predictions for fold {fold} ---\")\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        model = BaseCNN(CFG.model_name, pretrained=True, num_classes=CFG.target_size, dropout_p=CFG.dropout_p, image_alignment=CFG.image_alignment)\n",
    "        model.load_state_dict(torch.load(stage2_path))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        fold_oof_preds = []\n",
    "        fold_oof_labels = []\n",
    "        \n",
    "        # Use full validation set for OOF predictions\n",
    "        _, valid_loader = get_dataloaders(pd.DataFrame(), valid_df)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(valid_loader, desc=f\"OOF Prediction Fold {fold}\"):\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                probs = F.softmax(outputs, dim=1).cpu()\n",
    "\n",
    "                fold_oof_preds.append(probs)\n",
    "                fold_oof_labels.append(labels.cpu())\n",
    "\n",
    "        all_oof_preds.append(torch.cat(fold_oof_preds).numpy())\n",
    "        all_oof_labels.append(torch.cat(fold_oof_labels).numpy())\n",
    "        print(f\"   Finished OOF predictions for fold {fold}\")\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Upload artifact\n",
    "        artifact = wandb.Artifact(wandb_stage2_run.name, type='model')\n",
    "        artifact.add_file(stage2_path)\n",
    "        wandb.log_artifact(artifact)\n",
    "        wandb.finish()\n",
    "\n",
    "    if all_oof_preds and all_oof_labels:\n",
    "        print(\"\\nCalculating final OOF score...\")\n",
    "        final_oof_preds = np.concatenate(all_oof_preds)\n",
    "        final_oof_labels = np.concatenate(all_oof_labels)\n",
    "\n",
    "        oof_preds_tensor = torch.tensor(final_oof_preds, dtype=torch.float32)\n",
    "        oof_labels_tensor = torch.tensor(final_oof_labels, dtype=torch.float32)\n",
    "\n",
    "        log_oof_preds_tensor = torch.log(oof_preds_tensor)\n",
    "\n",
    "        kl_loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "        overall_oof_score = kl_loss_fn(log_oof_preds_tensor, oof_labels_tensor).item()\n",
    "\n",
    "        print(f\"\\nOverall OOF KL Score: {overall_oof_score:.4f}\")\n",
    "        print(f\"Average Fold Score: {np.mean(fold_scores):.4f}\")\n",
    "    else:\n",
    "        print(\"\\nCould not calculate OOF score because no predictions were generated.\")\n",
    "        overall_oof_score = None\n",
    "        \n",
    "    return overall_oof_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf35513",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4163262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data and creating folds...\n",
      "==================================================\n",
      "Starting EEG Data Processing Pipeline\n",
      "==================================================\n",
      "Skipping Parquet file creation as requested.\n",
      "Using 'max_vote_window' vote aggregation strategy.\n",
      "\n",
      "Processed train data saved to '/home/david/git/aicomp/data/processed/train_processed.csv'.\n",
      "Shape of the final dataframe: (17089, 13)\n",
      "\n",
      "Pipeline finished successfully!\n",
      "==================================================\n",
      "Train shape: (17089, 13)\n",
      "Targets ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
      "Folds created. Value counts per fold:\n",
      "fold\n",
      "0    4067\n",
      "1    3658\n",
      "2    3381\n",
      "4    3358\n",
      "3    2625\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data and creating folds...\")\n",
    "train_df = processor.process_data(vote_method=DATA_PREPARATION_VOTE_METHOD, skip_parquet=True)\n",
    "print('Train shape:', train_df.shape)\n",
    "print('Targets', list(TARGETS))\n",
    "\n",
    "fold_creator = KFoldCreator(n_splits=CFG.n_splits, seed=CFG.seed)\n",
    "train_df = fold_creator.create_folds(train_df, stratify_col='expert_consensus', group_col='patient_id')\n",
    "\n",
    "print(\"Folds created. Value counts per fold:\")\n",
    "print(train_df['fold'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18801280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Votes Distribution (Head):\n",
      "0    12\n",
      "1    14\n",
      "2     1\n",
      "3     1\n",
      "4     2\n",
      "Name: total_votes, dtype: int64\n",
      "Stage 1 Data (Low Votes < 10): 11150 samples\n",
      "Stage 2 Data (High Votes >= 10): 5939 samples\n",
      "\n",
      "==================== Processing FOLD 0 ====================\n",
      "Using device: cuda\n",
      "\n",
      "--- Starting stage1 | Fold 0 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/david/git/aicomp/notebooks/models/CNN/wandb/run-20251203_165732-v2opjn9a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/v2opjn9a' target=\"_blank\">twostage_inception_v3_multispec_dropout_0.1_mixup_alpha_2_stage1_fold0</a></strong> to <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/v2opjn9a' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/v2opjn9a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 16:57:33,518 :: timm.models._builder :: INFO :: Loading pretrained weights from Hugging Face hub (timm/inception_v3.tv_in1k)\n",
      "2025-12-03 16:57:33,721 :: timm.models._hub :: INFO :: [timm/inception_v3.tv_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "2025-12-03 16:57:33,757 :: timm.models._builder :: INFO :: Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --- Epoch 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stage1 Training E1:   0%|          | 0/268 [00:03<?, ?it/s]\n",
      "stage1 Validation:   0%|          | 0/128 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train Loss = 0.0059, Valid Loss = 0.0181, LR = 0.001000\n",
      "  New best model saved with validation loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/aicomp/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>▁</td></tr><tr><td>train/epoch_lr</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>val/kl_div</td><td>▁</td></tr><tr><td>val/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train/epoch_loss</td><td>0.00594</td></tr><tr><td>train/epoch_lr</td><td>0.001</td></tr><tr><td>train/loss</td><td>1.59398</td></tr><tr><td>val/kl_div</td><td>0.01811</td></tr><tr><td>val/loss</td><td>0.01811</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twostage_inception_v3_multispec_dropout_0.1_mixup_alpha_2_stage1_fold0</strong> at: <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/v2opjn9a' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/v2opjn9a</a><br> View project at: <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251203_165732-v2opjn9a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "--- Starting stage2 | Fold 0 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/david/git/aicomp/notebooks/models/CNN/wandb/run-20251203_165743-hstbaplo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/hstbaplo' target=\"_blank\">twostage_inception_v3_multispec_dropout_0.1_mixup_alpha_2_stage2_fold0</a></strong> to <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/hstbaplo' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/hstbaplo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 16:57:45,041 :: timm.models._builder :: INFO :: Loading pretrained weights from Hugging Face hub (timm/inception_v3.tv_in1k)\n",
      "2025-12-03 16:57:45,167 :: timm.models._hub :: INFO :: [timm/inception_v3.tv_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "2025-12-03 16:57:45,384 :: timm.models._builder :: INFO :: Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from /home/david/git/aicomp/models/multi_spec_cnn_two_stage/inception_v3/max_vote_window/stage1_fold0.pth...\n",
      "  --- Epoch 1/3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stage2 Training E1:   0%|          | 0/138 [00:03<?, ?it/s]\n",
      "stage2 Validation:   0%|          | 0/47 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train Loss = 0.0088, Valid Loss = 0.0373, LR = 0.000500\n",
      "  New best model saved with validation loss: 0.0373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/aicomp/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   --- Generating OOF predictions for fold 0 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 16:57:54,431 :: timm.models._builder :: INFO :: Loading pretrained weights from Hugging Face hub (timm/inception_v3.tv_in1k)\n",
      "2025-12-03 16:57:54,555 :: timm.models._hub :: INFO :: [timm/inception_v3.tv_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "2025-12-03 16:57:54,591 :: timm.models._builder :: INFO :: Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "OOF Prediction Fold 0: 100%|██████████| 128/128 [01:57<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Finished OOF predictions for fold 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>▁</td></tr><tr><td>train/epoch_lr</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>val/kl_div</td><td>▁</td></tr><tr><td>val/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train/epoch_loss</td><td>0.00881</td></tr><tr><td>train/epoch_lr</td><td>0.0005</td></tr><tr><td>train/loss</td><td>1.22034</td></tr><tr><td>val/kl_div</td><td>0.03733</td></tr><tr><td>val/loss</td><td>0.03733</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twostage_inception_v3_multispec_dropout_0.1_mixup_alpha_2_stage2_fold0</strong> at: <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/hstbaplo' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/hstbaplo</a><br> View project at: <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251203_165743-hstbaplo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Processing FOLD 1 ====================\n",
      "Using device: cuda\n",
      "\n",
      "--- Starting stage1 | Fold 1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/david/git/aicomp/notebooks/models/CNN/wandb/run-20251203_170005-w21lljmv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/w21lljmv' target=\"_blank\">twostage_inception_v3_multispec_dropout_0.1_mixup_alpha_2_stage1_fold1</a></strong> to <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/w21lljmv' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/w21lljmv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 17:00:06,407 :: timm.models._builder :: INFO :: Loading pretrained weights from Hugging Face hub (timm/inception_v3.tv_in1k)\n",
      "2025-12-03 17:00:06,534 :: timm.models._hub :: INFO :: [timm/inception_v3.tv_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "2025-12-03 17:00:06,573 :: timm.models._builder :: INFO :: Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --- Epoch 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stage1 Training E1:   0%|          | 0/275 [00:03<?, ?it/s]\n",
      "stage1 Validation:   0%|          | 0/115 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train Loss = 0.0081, Valid Loss = 0.0150, LR = 0.001000\n",
      "  New best model saved with validation loss: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/aicomp/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>▁</td></tr><tr><td>train/epoch_lr</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>val/kl_div</td><td>▁</td></tr><tr><td>val/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train/epoch_loss</td><td>0.00809</td></tr><tr><td>train/epoch_lr</td><td>0.001</td></tr><tr><td>train/loss</td><td>2.22526</td></tr><tr><td>val/kl_div</td><td>0.015</td></tr><tr><td>val/loss</td><td>0.015</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twostage_inception_v3_multispec_dropout_0.1_mixup_alpha_2_stage1_fold1</strong> at: <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/w21lljmv' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/w21lljmv</a><br> View project at: <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251203_170005-w21lljmv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "--- Starting stage2 | Fold 1 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/david/git/aicomp/notebooks/models/CNN/wandb/run-20251203_170018-wpj4f66w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/wpj4f66w' target=\"_blank\">twostage_inception_v3_multispec_dropout_0.1_mixup_alpha_2_stage2_fold1</a></strong> to <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/wpj4f66w' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/wpj4f66w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 17:00:20,101 :: timm.models._builder :: INFO :: Loading pretrained weights from Hugging Face hub (timm/inception_v3.tv_in1k)\n",
      "2025-12-03 17:00:20,234 :: timm.models._hub :: INFO :: [timm/inception_v3.tv_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "2025-12-03 17:00:20,271 :: timm.models._builder :: INFO :: Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from /home/david/git/aicomp/models/multi_spec_cnn_two_stage/inception_v3/max_vote_window/stage1_fold1.pth...\n",
      "  --- Epoch 1/3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stage2 Training E1:   0%|          | 0/144 [00:03<?, ?it/s]\n",
      "stage2 Validation:   0%|          | 0/41 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train Loss = 0.0125, Valid Loss = 0.0332, LR = 0.000500\n",
      "  New best model saved with validation loss: 0.0332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/aicomp/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   --- Generating OOF predictions for fold 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 17:00:29,694 :: timm.models._builder :: INFO :: Loading pretrained weights from Hugging Face hub (timm/inception_v3.tv_in1k)\n",
      "2025-12-03 17:00:29,819 :: timm.models._hub :: INFO :: [timm/inception_v3.tv_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "2025-12-03 17:00:29,871 :: timm.models._builder :: INFO :: Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "OOF Prediction Fold 1:  37%|███▋      | 43/115 [00:45<01:16,  1.06s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m overall_oof_score = \u001b[43mrun_two_stage_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATA_PREPARATION_VOTE_METHOD\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36mrun_two_stage_training\u001b[39m\u001b[34m(df, data_preparation_vote_method)\u001b[39m\n\u001b[32m     71\u001b[39m images = images.to(device)\n\u001b[32m     72\u001b[39m outputs = model(images)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m probs = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m fold_oof_preds.append(probs)\n\u001b[32m     76\u001b[39m fold_oof_labels.append(labels.cpu())\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "overall_oof_score = run_two_stage_training(train_df, DATA_PREPARATION_VOTE_METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b24bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Overall OOF KL Score from training: {overall_oof_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "aicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
