{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "014070dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PREPARATION_VOTE_METHOD = \"max_vote_window\" # \"max_vote_window\" or \"sum_and_normalize\". Decides how to aggregate the predictions of the overlapping windows\n",
    "PRETRAINED_MODEL_NAME_OR_PATH = \"tf_efficientnet_b0_ns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f15c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm \n",
    "import wandb\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "\n",
    "if bool(os.environ.get(\"KAGGLE_URL_BASE\", \"\")):\n",
    "  import sys\n",
    "  # running on kaggle\n",
    "  sys.path.insert(0, \"/kaggle/input/hsm-source-files\")\n",
    "else:\n",
    "  # running locally\n",
    "  sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"..\")))\n",
    "\n",
    "from src.datasets.multi_spectrogram import MultiSpectrogramDataset\n",
    "from src.utils.k_folds_creator import KFoldCreator\n",
    "from src.utils.utils import get_models_save_path, set_seeds, get_raw_data_dir, get_processed_data_dir\n",
    "from src.models.base_cnn import BaseCNN\n",
    "from src.utils.constants import Constants \n",
    "from src.datasets.eeg_processor import EEGDataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe5f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6d58a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 42\n",
    "    n_splits = 5\n",
    "    data_path = get_raw_data_dir()\n",
    "    train_eeg_spec_path = get_processed_data_dir() / \"eeg_spectrograms\" / \"train\" / \"cwt\"\n",
    "    \n",
    "    model_name = PRETRAINED_MODEL_NAME_OR_PATH\n",
    "    in_channels = 4  \n",
    "    target_size = 6 \n",
    "    \n",
    "    batch_size = 32\n",
    "    num_workers = 8\n",
    "    epochs = 5\n",
    "    lr = 1e-3\n",
    "    \n",
    "    img_size = (128, 256)\n",
    "\n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = Constants.TARGETS\n",
    "\n",
    "processor = EEGDataProcessor(raw_data_path=CFG.data_path, processed_data_path=get_processed_data_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c963bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(df, fold_id):\n",
    "    train_df = df[df['fold'] != fold_id].reset_index(drop=True)\n",
    "    valid_df = df[df['fold'] == fold_id].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = MultiSpectrogramDataset(\n",
    "        train_df, TARGETS, CFG.data_path, CFG.img_size, CFG.train_eeg_spec_path, mode='train'\n",
    "    )\n",
    "    valid_dataset = MultiSpectrogramDataset(\n",
    "        valid_df, TARGETS, CFG.data_path, CFG.img_size, CFG.train_eeg_spec_path, mode='train'\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da752de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(df, data_preparation_vote_method):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "    all_oof_preds = []\n",
    "    all_oof_labels = []\n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"\\n========== FOLD {fold} ==========\")\n",
    "\n",
    "        config = {\n",
    "            # Model\n",
    "            \"architecture\": CFG.model_name,\n",
    "            \"pretrained\": True,\n",
    "            # Data\n",
    "            \"fold\": fold,\n",
    "            \"features\": \"multi_spectrograms\",\n",
    "            \"window_selection\": DATA_PREPARATION_VOTE_METHOD,\n",
    "            # Training\n",
    "            \"optimizer\": \"AdamW\",\n",
    "            \"learning_rate\": CFG.lr,\n",
    "            \"batch_size\": CFG.batch_size,\n",
    "            \"epochs\": CFG.epochs,\n",
    "            \"seed\": CFG.seed,\n",
    "            \"scheduler\": \"CosineAnnealingLR\" \n",
    "        }\n",
    "\n",
    "        wandb.init(\n",
    "            project=\"hms-aicomp-cnn-multispec\",\n",
    "            name=f\"{CFG.model_name}-multispec-fold{fold}\", \n",
    "            tags=[f'fold{fold}'],\n",
    "            config=config\n",
    "        )\n",
    "\n",
    "        model = BaseCNN(CFG.model_name, pretrained=True, num_classes=CFG.target_size)\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=CFG.epochs)\n",
    "        loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "        train_loader, valid_loader = get_dataloaders(df, fold)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_path = None\n",
    "\n",
    "        for epoch in range(CFG.epochs):\n",
    "            print(f\"  --- Epoch {epoch+1}/{CFG.epochs} ---\")\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with autocast(device_type=device.type, dtype=torch.float16):\n",
    "                    outputs = model(images)\n",
    "                    log_probs = F.log_softmax(outputs, dim=1)\n",
    "                    loss = loss_fn(log_probs, labels)\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                train_loss += loss.item() * images.size(0)\n",
    "\n",
    "                wandb.log({\"train/loss\": loss.item()})\n",
    "\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "\n",
    "            model.eval()\n",
    "            valid_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in tqdm(valid_loader, desc=\"Validation\"):\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                    with autocast(device_type=device.type, dtype=torch.float16):\n",
    "                        outputs = model(images)\n",
    "                        log_probs = F.log_softmax(outputs, dim=1)\n",
    "                        loss = loss_fn(log_probs, labels)\n",
    "\n",
    "                    valid_loss += loss.item() * images.size(0)\n",
    "\n",
    "            valid_loss /= len(valid_loader.dataset)\n",
    "            \n",
    "            epoch_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"   Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Valid Loss = {valid_loss:.4f}, LR = {epoch_lr:.6f}\")\n",
    "\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train/epoch_loss\": train_loss,\n",
    "                \"val/loss\": valid_loss,\n",
    "                \"val/kl_div\": valid_loss,\n",
    "                \"train/epoch_lr\": epoch_lr\n",
    "            })\n",
    "\n",
    "            if valid_loss < best_val_loss:\n",
    "                best_val_loss = valid_loss\n",
    "                best_model_path = get_models_save_path() / \"multi_spec_cnn\" / CFG.model_name / data_preparation_vote_method / f'best_model_fold{fold}.pth'\n",
    "                best_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f\"  New best model saved with validation loss: {best_val_loss:.4f}\")\n",
    "            scheduler.step()\n",
    "\n",
    "        print(f\"   --- Generating OOF predictions for fold {fold} ---\")\n",
    "        if best_model_path:\n",
    "            model.load_state_dict(torch.load(best_model_path))\n",
    "            model.eval()\n",
    "\n",
    "            fold_oof_preds = []\n",
    "            fold_oof_labels = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, labels in tqdm(valid_loader, desc=f\"OOF Prediction Fold {fold}\"):\n",
    "                    images = images.to(device)\n",
    "                    outputs = model(images)\n",
    "                    probs = F.softmax(outputs, dim=1).cpu()\n",
    "\n",
    "                    fold_oof_preds.append(probs)\n",
    "                    fold_oof_labels.append(labels.cpu())\n",
    "\n",
    "            all_oof_preds.append(torch.cat(fold_oof_preds).numpy())\n",
    "            all_oof_labels.append(torch.cat(fold_oof_labels).numpy())\n",
    "            print(f\"   Finished OOF predictions for fold {fold}\")\n",
    "        else:\n",
    "            raise RuntimeError(\"Best model path is None, cannot generate OOF predictions.\")\n",
    "\n",
    "\n",
    "        wandb.summary['best_val_kl_div'] = best_val_loss\n",
    "\n",
    "        if best_model_path:\n",
    "            artifact = wandb.Artifact(f'{CFG.model_name}-fold{fold}', type='model')\n",
    "            artifact.add_file(best_model_path)\n",
    "            wandb.log_artifact(artifact)\n",
    "            print(f\"\\nLogged artifact for fold {fold} with best validation loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            print(\"\\nNo best model was saved during training for this fold.\")\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "    if all_oof_preds and all_oof_labels:\n",
    "        print(\"\\nCalculating final OOF score...\")\n",
    "        final_oof_preds = np.concatenate(all_oof_preds)\n",
    "        final_oof_labels = np.concatenate(all_oof_labels)\n",
    "\n",
    "        oof_preds_tensor = torch.tensor(final_oof_preds, dtype=torch.float32)\n",
    "        oof_labels_tensor = torch.tensor(final_oof_labels, dtype=torch.float32)\n",
    "\n",
    "        log_oof_preds_tensor = torch.log(oof_preds_tensor)\n",
    "\n",
    "        kl_loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "        overall_oof_score = kl_loss_fn(log_oof_preds_tensor, oof_labels_tensor).item()\n",
    "\n",
    "        print(f\"\\nOverall OOF KL Score: {overall_oof_score:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nCould not calculate OOF score because no predictions were generated.\")\n",
    "        \n",
    "    return overall_oof_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f1540d",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a11f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing data and creating folds...\")\n",
    "train_df = processor.process_data(vote_method=DATA_PREPARATION_VOTE_METHOD, skip_parquet=True)\n",
    "print('Train shape:', train_df.shape)\n",
    "print('Targets', list(TARGETS))\n",
    "\n",
    "fold_creator = KFoldCreator(n_splits=CFG.n_splits, seed=CFG.seed)\n",
    "train_df = fold_creator.create_folds(train_df, stratify_col='expert_consensus', group_col='patient_id')\n",
    "\n",
    "print(\"Folds created. Value counts per fold:\")\n",
    "print(train_df['fold'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1667d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.\n"
     ]
    }
   ],
   "source": [
    "overall_oof_score = run_training(train_df, DATA_PREPARATION_VOTE_METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad353ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Overall OOF KL Score from training: {overall_oof_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
