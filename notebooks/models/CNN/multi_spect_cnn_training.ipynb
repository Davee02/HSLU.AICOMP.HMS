{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "014070dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PREPARATION_VOTE_METHOD = \"max_vote_window\" # \"max_vote_window\" or \"sum_and_normalize\". Decides how to aggregate the predictions of the overlapping windows\n",
    "PRETRAINED_MODEL_NAME_OR_PATH = \"inception_v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a7f15c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/aicomp/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/david/miniconda3/envs/aicomp/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "2025-11-14 13:28:38,665 :: root :: INFO :: Initialising Utils\n",
      "2025-11-14 13:28:40,887 :: root :: INFO :: Initialising Datasets\n",
      "2025-11-14 13:28:41,591 :: root :: INFO :: Initialising Models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping module tcn due to missing dependency: No module named 'pytorch_tcn'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm \n",
    "import wandb\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "\n",
    "if bool(os.environ.get(\"KAGGLE_URL_BASE\", \"\")):\n",
    "  import sys\n",
    "  # running on kaggle\n",
    "  sys.path.insert(0, \"/kaggle/input/hsm-source-files\")\n",
    "else:\n",
    "  # running locally\n",
    "  sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"..\")))\n",
    "\n",
    "from src.datasets.multi_spectrogram import MultiSpectrogramDataset\n",
    "from src.utils.k_folds_creator import KFoldCreator\n",
    "from src.utils.utils import get_models_save_path, set_seeds, get_raw_data_dir, get_processed_data_dir\n",
    "from src.models.base_cnn import BaseCNN\n",
    "from src.utils.constants import Constants \n",
    "from src.datasets.eeg_processor import EEGDataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fbe5f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidhodel\u001b[0m (\u001b[33mhms-hslu-aicomp-hs25\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d58a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 42\n",
    "    n_splits = 5\n",
    "    data_path = get_raw_data_dir()\n",
    "    train_eeg_spec_path = get_processed_data_dir() / \"eeg_spectrograms\" / \"train\" / \"cwt\"\n",
    "    \n",
    "    model_name = PRETRAINED_MODEL_NAME_OR_PATH\n",
    "    target_size = 6 \n",
    "    \n",
    "    batch_size = 32\n",
    "    num_workers = 8\n",
    "    epochs = 10\n",
    "    lr = 1e-3\n",
    "    dropout_p = 0.1\n",
    "    \n",
    "    img_size = (128, 256)\n",
    "\n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa77feb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor initialized.\n",
      "Raw data path: '/home/david/git/aicomp/data'\n",
      "Processed data path: '/home/david/git/aicomp/data/processed'\n"
     ]
    }
   ],
   "source": [
    "TARGETS = Constants.TARGETS\n",
    "\n",
    "processor = EEGDataProcessor(raw_data_path=CFG.data_path, processed_data_path=get_processed_data_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c963bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(df, fold_id):\n",
    "    train_df = df[df['fold'] != fold_id].reset_index(drop=True)\n",
    "    valid_df = df[df['fold'] == fold_id].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = MultiSpectrogramDataset(\n",
    "        train_df, TARGETS, CFG.data_path, CFG.img_size, CFG.train_eeg_spec_path, mode='train', apply_augmentations=True\n",
    "    )\n",
    "    valid_dataset = MultiSpectrogramDataset(\n",
    "        valid_df, TARGETS, CFG.data_path, CFG.img_size, CFG.train_eeg_spec_path, mode='train', apply_augmentations=False\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da752de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(df, data_preparation_vote_method):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "    all_oof_preds = []\n",
    "    all_oof_labels = []\n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"\\n========== FOLD {fold} ==========\")\n",
    "\n",
    "        config = {\n",
    "            # Model\n",
    "            \"architecture\": CFG.model_name,\n",
    "            \"pretrained\": True,\n",
    "            # Data\n",
    "            \"fold\": fold,\n",
    "            \"features\": \"multi_spectrograms\",\n",
    "            \"window_selection\": DATA_PREPARATION_VOTE_METHOD,\n",
    "            \"use_augmentations\": True,\n",
    "            # Training\n",
    "            \"optimizer\": \"AdamW\",\n",
    "            \"learning_rate\": CFG.lr,\n",
    "            \"batch_size\": CFG.batch_size,\n",
    "            \"epochs\": CFG.epochs,\n",
    "            \"seed\": CFG.seed,\n",
    "            \"scheduler\": \"CosineAnnealingLR\",\n",
    "            \"dropout_p\": CFG.dropout_p,\n",
    "        }\n",
    "\n",
    "        wandb.init(\n",
    "            project=\"hms-aicomp-cnn-multispec\",\n",
    "            name=f\"{CFG.model_name}-multispec-dropout_0.1-augmentations-epochs_10-fold{fold}\", \n",
    "            tags=[f'fold{fold}'],\n",
    "            config=config\n",
    "        )\n",
    "\n",
    "        model = BaseCNN(CFG.model_name, pretrained=True, num_classes=CFG.target_size, dropout_p=CFG.dropout_p)\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=CFG.epochs)\n",
    "        loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "        train_loader, valid_loader = get_dataloaders(df, fold)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_path = None\n",
    "\n",
    "        for epoch in range(CFG.epochs):\n",
    "            print(f\"  --- Epoch {epoch+1}/{CFG.epochs} ---\")\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with autocast(device_type=device.type, dtype=torch.float16):\n",
    "                    outputs = model(images)\n",
    "                    log_probs = F.log_softmax(outputs, dim=1)\n",
    "                    loss = loss_fn(log_probs, labels)\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                train_loss += loss.item() * images.size(0)\n",
    "\n",
    "                wandb.log({\"train/loss\": loss.item()})\n",
    "\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "\n",
    "            model.eval()\n",
    "            valid_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in tqdm(valid_loader, desc=\"Validation\"):\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                    with autocast(device_type=device.type, dtype=torch.float16):\n",
    "                        outputs = model(images)\n",
    "                        log_probs = F.log_softmax(outputs, dim=1)\n",
    "                        loss = loss_fn(log_probs, labels)\n",
    "\n",
    "                    valid_loss += loss.item() * images.size(0)\n",
    "\n",
    "            valid_loss /= len(valid_loader.dataset)\n",
    "            \n",
    "            epoch_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"   Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Valid Loss = {valid_loss:.4f}, LR = {epoch_lr:.6f}\")\n",
    "\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train/epoch_loss\": train_loss,\n",
    "                \"val/loss\": valid_loss,\n",
    "                \"val/kl_div\": valid_loss,\n",
    "                \"train/epoch_lr\": epoch_lr\n",
    "            })\n",
    "\n",
    "            if valid_loss < best_val_loss:\n",
    "                best_val_loss = valid_loss\n",
    "                best_model_path = get_models_save_path() / \"multi_spec_cnn\" / CFG.model_name / data_preparation_vote_method / f'best_model_fold{fold}.pth'\n",
    "                best_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f\"  New best model saved with validation loss: {best_val_loss:.4f}\")\n",
    "            scheduler.step()\n",
    "\n",
    "        print(f\"   --- Generating OOF predictions for fold {fold} ---\")\n",
    "        if best_model_path:\n",
    "            model.load_state_dict(torch.load(best_model_path))\n",
    "            model.eval()\n",
    "\n",
    "            fold_oof_preds = []\n",
    "            fold_oof_labels = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, labels in tqdm(valid_loader, desc=f\"OOF Prediction Fold {fold}\"):\n",
    "                    images = images.to(device)\n",
    "                    outputs = model(images)\n",
    "                    probs = F.softmax(outputs, dim=1).cpu()\n",
    "\n",
    "                    fold_oof_preds.append(probs)\n",
    "                    fold_oof_labels.append(labels.cpu())\n",
    "\n",
    "            all_oof_preds.append(torch.cat(fold_oof_preds).numpy())\n",
    "            all_oof_labels.append(torch.cat(fold_oof_labels).numpy())\n",
    "            print(f\"   Finished OOF predictions for fold {fold}\")\n",
    "        else:\n",
    "            raise RuntimeError(\"Best model path is None, cannot generate OOF predictions.\")\n",
    "\n",
    "\n",
    "        wandb.summary['best_val_kl_div'] = best_val_loss\n",
    "\n",
    "        if best_model_path:\n",
    "            artifact = wandb.Artifact(f'{CFG.model_name}-fold{fold}', type='model')\n",
    "            artifact.add_file(best_model_path)\n",
    "            wandb.log_artifact(artifact)\n",
    "            print(f\"\\nLogged artifact for fold {fold} with best validation loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            print(\"\\nNo best model was saved during training for this fold.\")\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "    if all_oof_preds and all_oof_labels:\n",
    "        print(\"\\nCalculating final OOF score...\")\n",
    "        final_oof_preds = np.concatenate(all_oof_preds)\n",
    "        final_oof_labels = np.concatenate(all_oof_labels)\n",
    "\n",
    "        oof_preds_tensor = torch.tensor(final_oof_preds, dtype=torch.float32)\n",
    "        oof_labels_tensor = torch.tensor(final_oof_labels, dtype=torch.float32)\n",
    "\n",
    "        log_oof_preds_tensor = torch.log(oof_preds_tensor)\n",
    "\n",
    "        kl_loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "        overall_oof_score = kl_loss_fn(log_oof_preds_tensor, oof_labels_tensor).item()\n",
    "\n",
    "        print(f\"\\nOverall OOF KL Score: {overall_oof_score:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nCould not calculate OOF score because no predictions were generated.\")\n",
    "        \n",
    "    return overall_oof_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f1540d",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a11f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data and creating folds...\n",
      "==================================================\n",
      "Starting EEG Data Processing Pipeline\n",
      "==================================================\n",
      "Skipping Parquet file creation as requested.\n",
      "Using 'max_vote_window' vote aggregation strategy.\n",
      "\n",
      "Processed train data saved to '/home/david/git/aicomp/data/processed/train_processed.csv'.\n",
      "Shape of the final dataframe: (17089, 12)\n",
      "\n",
      "Pipeline finished successfully!\n",
      "==================================================\n",
      "Train shape: (17089, 12)\n",
      "Targets ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
      "Folds created. Value counts per fold:\n",
      "fold\n",
      "0    4067\n",
      "1    3658\n",
      "2    3381\n",
      "4    3358\n",
      "3    2625\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data and creating folds...\")\n",
    "train_df = processor.process_data(vote_method=DATA_PREPARATION_VOTE_METHOD, skip_parquet=True)\n",
    "print('Train shape:', train_df.shape)\n",
    "print('Targets', list(TARGETS))\n",
    "\n",
    "fold_creator = KFoldCreator(n_splits=CFG.n_splits, seed=CFG.seed)\n",
    "train_df = fold_creator.create_folds(train_df, stratify_col='expert_consensus', group_col='patient_id')\n",
    "\n",
    "print(\"Folds created. Value counts per fold:\")\n",
    "print(train_df['fold'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1667d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "========== FOLD 0 ==========\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/david/git/aicomp/notebooks/models/CNN/wandb/run-20251114_132845-aoxnkdh3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/aoxnkdh3' target=\"_blank\">inception_v3-multispec-dropout_0.1-fold0</a></strong> to <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/aoxnkdh3' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/aoxnkdh3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-14 13:28:47,263 :: timm.models._builder :: INFO :: Loading pretrained weights from Hugging Face hub (timm/inception_v3.tv_in1k)\n",
      "2025-11-14 13:28:47,475 :: timm.models._hub :: INFO :: [timm/inception_v3.tv_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "2025-11-14 13:28:47,934 :: timm.models._builder :: INFO :: Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  --- Epoch 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 406/406 [03:15<00:00,  2.08it/s]\n",
      "Validation: 100%|██████████| 128/128 [00:37<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1: Train Loss = 0.8128, Valid Loss = 0.9825, LR = 0.001000\n",
      "  New best model saved with validation loss: 0.9825\n",
      "  --- Epoch 2/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 406/406 [03:09<00:00,  2.14it/s]\n",
      "Validation: 100%|██████████| 128/128 [00:31<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 2: Train Loss = 0.6486, Valid Loss = 1.0225, LR = 0.000905\n",
      "  --- Epoch 3/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 406/406 [03:01<00:00,  2.23it/s]\n",
      "Validation: 100%|██████████| 128/128 [00:27<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 3: Train Loss = 0.5568, Valid Loss = 0.8608, LR = 0.000655\n",
      "  New best model saved with validation loss: 0.8608\n",
      "  --- Epoch 4/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 406/406 [03:04<00:00,  2.20it/s]\n",
      "Validation: 100%|██████████| 128/128 [00:30<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 4: Train Loss = 0.4532, Valid Loss = 0.8453, LR = 0.000345\n",
      "  New best model saved with validation loss: 0.8453\n",
      "  --- Epoch 5/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 406/406 [03:09<00:00,  2.14it/s]\n",
      "Validation: 100%|██████████| 128/128 [00:29<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Train Loss = 0.3333, Valid Loss = 0.8122, LR = 0.000095\n",
      "  New best model saved with validation loss: 0.8122\n",
      "   --- Generating OOF predictions for fold 0 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OOF Prediction Fold 0: 100%|██████████| 128/128 [01:42<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Finished OOF predictions for fold 0\n",
      "\n",
      "Logged artifact for fold 0 with best validation loss: 0.8122\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train/epoch_loss</td><td>█▆▄▃▁</td></tr><tr><td>train/epoch_lr</td><td>█▇▅▃▁</td></tr><tr><td>train/loss</td><td>▆▅███▆▅▆▆▃▆▄▅▃▄▃▃▄▃▅▅▃▃▄▄▂▄▂▄▃▂▃▂▁▁▂▂▁▂▂</td></tr><tr><td>val/kl_div</td><td>▇█▃▂▁</td></tr><tr><td>val/loss</td><td>▇█▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_kl_div</td><td>0.8122</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>train/epoch_loss</td><td>0.33335</td></tr><tr><td>train/epoch_lr</td><td>0.0001</td></tr><tr><td>train/loss</td><td>0.24617</td></tr><tr><td>val/kl_div</td><td>0.8122</td></tr><tr><td>val/loss</td><td>0.8122</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">inception_v3-multispec-dropout_0.1-fold0</strong> at: <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/aoxnkdh3' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec/runs/aoxnkdh3</a><br> View project at: <a href='https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec' target=\"_blank\">https://wandb.ai/hms-hslu-aicomp-hs25/hms-aicomp-cnn-multispec</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251114_132845-aoxnkdh3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating final OOF score...\n",
      "\n",
      "Overall OOF KL Score: 0.8121\n"
     ]
    }
   ],
   "source": [
    "overall_oof_score = run_training(train_df, DATA_PREPARATION_VOTE_METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad353ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall OOF KL Score from training: 0.8121\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overall OOF KL Score from training: {overall_oof_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
