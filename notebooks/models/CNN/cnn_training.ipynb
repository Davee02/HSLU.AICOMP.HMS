{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "014070dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PREPARATION_VOTE_METHOD = \"max_vote_window\" # \"max_vote_window\" or \"sum_and_normalize\". Decides how to aggregate the predictions of the overlapping windows\n",
    "PRETRAINED_MODEL_NAME_OR_PATH = \"tf_efficientnet_b0_ns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a7f15c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/aicomp/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/david/miniconda3/envs/aicomp/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "2025-11-01 15:51:24,907 :: root :: INFO :: Initialising Utils\n",
      "2025-11-01 15:51:26,033 :: root :: INFO :: Initialising Datasets\n",
      "2025-11-01 15:51:26,060 :: root :: INFO :: Initialising Models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping module tcn due to missing dependency: No module named 'pytorch_tcn'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm \n",
    "import wandb\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import sys\n",
    "\n",
    "if bool(os.environ.get(\"KAGGLE_URL_BASE\", \"\")):\n",
    "  import sys\n",
    "  # running on kaggle\n",
    "  sys.path.insert(0, \"/kaggle/input/hsm-source-files\")\n",
    "else:\n",
    "  # running locally\n",
    "  sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"..\")))\n",
    "\n",
    "from src.datasets.spectrogram_dataset import SpectrogramDataset\n",
    "from src.utils.k_folds_creator import KFoldCreator\n",
    "from src.utils.utils import get_models_save_path, set_seeds, get_raw_data_dir, get_processed_data_dir\n",
    "from src.models.base_cnn import BaseCNN\n",
    "from src.utils.constants import Constants \n",
    "from src.datasets.eeg_processor import EEGDataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fbe5f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidhodel\u001b[0m (\u001b[33mhms-hslu-aicomp-hs25\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d58a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 42\n",
    "    n_splits = 5\n",
    "    data_path = get_raw_data_dir()\n",
    "    \n",
    "    model_name = PRETRAINED_MODEL_NAME_OR_PATH\n",
    "    in_channels = 4  \n",
    "    target_size = 6 \n",
    "    \n",
    "    batch_size = 32\n",
    "    num_workers = 8\n",
    "    epochs = 5\n",
    "    lr = 1e-3\n",
    "    \n",
    "    # This is the base size of each channel, not the final reshaped size\n",
    "    img_size = (128, 256)\n",
    "\n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa77feb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor initialized.\n",
      "Raw data path: '/home/david/git/aicomp/data'\n",
      "Processed data path: '/home/david/git/aicomp/data/processed'\n"
     ]
    }
   ],
   "source": [
    "TARGETS = Constants.TARGETS\n",
    "\n",
    "processor = EEGDataProcessor(raw_data_path=CFG.data_path, processed_data_path=get_processed_data_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c963bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(df, fold_id):\n",
    "    train_df = df[df['fold'] != fold_id].reset_index(drop=True)\n",
    "    valid_df = df[df['fold'] == fold_id].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = SpectrogramDataset(train_df, TARGETS, CFG.data_path, CFG.img_size, mode='train')\n",
    "    valid_dataset = SpectrogramDataset(valid_df, TARGETS, CFG.data_path, CFG.img_size, mode='train')\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da752de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(df, data_preparation_vote_method):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    all_oof_preds = []\n",
    "    all_oof_labels = []\n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"\\n========== FOLD {fold} ==========\")\n",
    "\n",
    "        config = {\n",
    "            # Model\n",
    "            \"architecture\": CFG.model_name,\n",
    "            \"pretrained\": True,\n",
    "            # Data\n",
    "            \"fold\": fold,\n",
    "            \"features\": \"spectrograms\",\n",
    "            \"window_selection\": \"sum_and_normalize\",\n",
    "            # Training\n",
    "            \"optimizer\": \"AdamW\",\n",
    "            \"learning_rate\": CFG.lr,\n",
    "            \"batch_size\": CFG.batch_size,\n",
    "            \"epochs\": CFG.epochs,\n",
    "            \"seed\": CFG.seed,\n",
    "            \"scheduler\": \"CosineAnnealingLR\" \n",
    "        }\n",
    "\n",
    "        wandb.init(\n",
    "            project=\"hms-aicomp-cnn\",\n",
    "            name=f\"{CFG.model_name}-spec-fold{fold}\", \n",
    "            tags=[f'fold{fold}'],\n",
    "            config=config\n",
    "        )\n",
    "\n",
    "        model = BaseCNN(CFG.model_name, pretrained=True, num_classes=CFG.target_size)\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=CFG.epochs)\n",
    "        loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "        train_loader, valid_loader = get_dataloaders(df, fold)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_path = None\n",
    "\n",
    "        for epoch in range(CFG.epochs):\n",
    "            print(f\"  --- Epoch {epoch+1}/{CFG.epochs} ---\")\n",
    "\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                log_probs = F.log_softmax(outputs, dim=1)\n",
    "                loss = loss_fn(log_probs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item() * images.size(0)\n",
    "\n",
    "                wandb.log({\"train/loss\": loss.item()})\n",
    "\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "\n",
    "            model.eval()\n",
    "            valid_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in tqdm(valid_loader, desc=\"Validation\"):\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    log_probs = F.log_softmax(outputs, dim=1)\n",
    "                    loss = loss_fn(log_probs, labels)\n",
    "                    valid_loss += loss.item() * images.size(0)\n",
    "\n",
    "            valid_loss /= len(valid_loader.dataset)\n",
    "            \n",
    "            epoch_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"   Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Valid Loss = {valid_loss:.4f}, LR = {epoch_lr:.6f}\")\n",
    "\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train/epoch_loss\": train_loss,\n",
    "                \"val/loss\": valid_loss,\n",
    "                \"val/kl_div\": valid_loss,\n",
    "                \"train/epoch_lr\": epoch_lr\n",
    "            })\n",
    "\n",
    "            if valid_loss < best_val_loss:\n",
    "                best_val_loss = valid_loss\n",
    "                best_model_path = get_models_save_path() / \"base_cnn\" / CFG.model_name / data_preparation_vote_method / f'best_model_fold{fold}.pth'\n",
    "                best_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f\"  New best model saved with validation loss: {best_val_loss:.4f}\")\n",
    "            scheduler.step()\n",
    "\n",
    "        print(f\"   --- Generating OOF predictions for fold {fold} ---\")\n",
    "        if best_model_path:\n",
    "            model.load_state_dict(torch.load(best_model_path))\n",
    "            model.eval()\n",
    "\n",
    "            fold_oof_preds = []\n",
    "            fold_oof_labels = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, labels in tqdm(valid_loader, desc=f\"OOF Prediction Fold {fold}\"):\n",
    "                    images = images.to(device)\n",
    "                    outputs = model(images)\n",
    "                    probs = F.softmax(outputs, dim=1).cpu()\n",
    "\n",
    "                    fold_oof_preds.append(probs)\n",
    "                    fold_oof_labels.append(labels.cpu())\n",
    "\n",
    "            all_oof_preds.append(torch.cat(fold_oof_preds).numpy())\n",
    "            all_oof_labels.append(torch.cat(fold_oof_labels).numpy())\n",
    "            print(f\"   Finished OOF predictions for fold {fold}\")\n",
    "        else:\n",
    "            raise RuntimeError(\"Best model path is None, cannot generate OOF predictions.\")\n",
    "\n",
    "\n",
    "        wandb.summary['best_val_kl_div'] = best_val_loss\n",
    "\n",
    "        if best_model_path:\n",
    "            artifact = wandb.Artifact(f'{CFG.model_name}-fold{fold}', type='model')\n",
    "            artifact.add_file(best_model_path)\n",
    "            wandb.log_artifact(artifact)\n",
    "            print(f\"\\nLogged artifact for fold {fold} with best validation loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            print(\"\\nNo best model was saved during training for this fold.\")\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "    if all_oof_preds and all_oof_labels:\n",
    "        print(\"\\nCalculating final OOF score...\")\n",
    "        final_oof_preds = np.concatenate(all_oof_preds)\n",
    "        final_oof_labels = np.concatenate(all_oof_labels)\n",
    "\n",
    "        oof_preds_tensor = torch.tensor(final_oof_preds, dtype=torch.float32)\n",
    "        oof_labels_tensor = torch.tensor(final_oof_labels, dtype=torch.float32)\n",
    "\n",
    "        log_oof_preds_tensor = torch.log(oof_preds_tensor)\n",
    "\n",
    "        kl_loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "        overall_oof_score = kl_loss_fn(log_oof_preds_tensor, oof_labels_tensor).item()\n",
    "\n",
    "        print(f\"\\nOverall OOF KL Score: {overall_oof_score:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nCould not calculate OOF score because no predictions were generated.\")\n",
    "        \n",
    "    return overall_oof_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f1540d",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a11f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data and creating folds...\n",
      "==================================================\n",
      "Starting EEG Data Processing Pipeline\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Parquet file creation as requested.\n",
      "Using 'max_vote_window' vote aggregation strategy.\n",
      "\n",
      "Processed train data saved to '/home/david/git/aicomp/data/processed/train_processed.csv'.\n",
      "Shape of the final dataframe: (17089, 12)\n",
      "\n",
      "Pipeline finished successfully!\n",
      "==================================================\n",
      "Train shape: (17089, 12)\n",
      "Targets ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
      "Folds created. Value counts per fold:\n",
      "fold\n",
      "0    4067\n",
      "1    3658\n",
      "2    3381\n",
      "4    3358\n",
      "3    2625\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data and creating folds...\")\n",
    "train_df = processor.process_data(vote_method=DATA_PREPARATION_VOTE_METHOD, skip_parquet=True)\n",
    "print('Train shape:', train_df.shape)\n",
    "print('Targets', list(TARGETS))\n",
    "\n",
    "fold_creator = KFoldCreator(n_splits=CFG.n_splits, seed=CFG.seed)\n",
    "train_df = fold_creator.create_folds(train_df, stratify_col='expert_consensus', group_col='patient_id')\n",
    "\n",
    "print(\"Folds created. Value counts per fold:\")\n",
    "print(train_df['fold'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1667d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_oof_score = run_training(train_df, DATA_PREPARATION_VOTE_METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad353ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Overall OOF KL Score from training: {overall_oof_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
