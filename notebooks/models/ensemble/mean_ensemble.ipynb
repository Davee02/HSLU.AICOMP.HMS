{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXISTING_CHECKPOINT_KAGGLE_DATASET_ID = \"hsm-models\"\n",
    "DATA_PREPARATION_VOTE_METHOD = \"max_vote_window\" # \"max_vote_window\" or \"sum_and_normalize\". Decides how to aggregate the predictions of the overlapping windows\n",
    "DATA_SOURCE = \"cv\" # \"cv\" or \"test\". On Kaggle, this is autpmatically set to \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "if bool(os.environ.get(\"KAGGLE_URL_BASE\", \"\")):\n",
    "  import sys\n",
    "  # running on kaggle\n",
    "  sys.path.insert(0, \"/kaggle/input/hsm-source-files\")\n",
    "else:\n",
    "  # running locally\n",
    "  sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"..\")))\n",
    "\n",
    "from src.utils.utils import get_raw_data_dir, get_processed_data_dir, get_submission_csv_path, get_models_save_path, set_seeds, running_in_kaggle\n",
    "from src.utils.constants import Constants\n",
    "\n",
    "from src.utils.k_folds_creator import KFoldCreator\n",
    "from src.datasets.multi_spectrogram import MultiSpectrogramDataset\n",
    "from src.datasets.eeg_dataset_montage import EEGDatasetMontage\n",
    "from src.models.base_cnn import BaseCNN\n",
    "from src.models.gru_convolution_attention import NodeAttentionModel\n",
    "from src.utils.eeg_spectrogram_creator import EEGSpectrogramGenerator\n",
    "from src.datasets.eeg_processor import EEGDataProcessor\n",
    "\n",
    "set_seeds(Constants.SEED)\n",
    "\n",
    "if running_in_kaggle():\n",
    "  DATA_SOURCE = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eeg_spectrograms(eeg_spectrograms_path, raw_eegs_path, data_df):\n",
    "  os.makedirs(eeg_spectrograms_path, exist_ok=True)\n",
    "  existing_specs = len(list(eeg_spectrograms_path.glob(\"*.npy\")))\n",
    "\n",
    "  eeg_ids = data_df[\"eeg_id\"].unique()\n",
    "  if existing_specs >= len(eeg_ids):\n",
    "    print(\"EEG Spectrograms already created.\")\n",
    "    return\n",
    "  else:\n",
    "    spectrogram_creator = EEGSpectrogramGenerator([\"cwt\"])\n",
    "    for eeg_id in tqdm(eeg_ids, desc=\"Generating EEG Spectrograms\"):\n",
    "        eeg_path = os.path.join(raw_eegs_path, f\"{eeg_id}.parquet\")\n",
    "        eeg = pd.read_parquet(eeg_path)\n",
    "        spectrograms = spectrogram_creator.generate(eeg)\n",
    "        np.save(eeg_spectrograms_path / f\"{eeg_id}.npy\", spectrograms['cwt']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor initialized.\n",
      "Raw data path: '/home/david/git/aicomp/data'\n",
      "Processed data path: '/home/david/git/aicomp/data/processed'\n",
      "==================================================\n",
      "Starting EEG Data Processing Pipeline\n",
      "==================================================\n",
      "Skipping Parquet file creation as requested.\n",
      "Using 'max_vote_window' vote aggregation strategy.\n",
      "\n",
      "Processed train data saved to '/home/david/git/aicomp/data/processed/train_processed.csv'.\n",
      "Shape of the final dataframe: (17089, 12)\n",
      "\n",
      "Pipeline finished successfully!\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>expert_consensus</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "      <th>min_offset</th>\n",
       "      <th>max_offset</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>568657</td>\n",
       "      <td>789577333</td>\n",
       "      <td>20654</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>582999</td>\n",
       "      <td>1552638400</td>\n",
       "      <td>20230</td>\n",
       "      <td>LPD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642382</td>\n",
       "      <td>14960202</td>\n",
       "      <td>5955</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>751790</td>\n",
       "      <td>618728447</td>\n",
       "      <td>38549</td>\n",
       "      <td>GPD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>908.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>778705</td>\n",
       "      <td>52296320</td>\n",
       "      <td>40955</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eeg_id  spectrogram_id  patient_id expert_consensus  seizure_vote  \\\n",
       "0  568657       789577333       20654            Other           0.0   \n",
       "1  582999      1552638400       20230              LPD           0.0   \n",
       "2  642382        14960202        5955            Other           0.0   \n",
       "3  751790       618728447       38549              GPD           0.0   \n",
       "4  778705        52296320       40955            Other           0.0   \n",
       "\n",
       "   lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote  min_offset  \\\n",
       "0  0.000000      0.25   0.000000   0.166667    0.583333         0.0   \n",
       "1  0.857143      0.00   0.071429   0.000000    0.071429         0.0   \n",
       "2  0.000000      0.00   0.000000   0.000000    1.000000      1008.0   \n",
       "3  0.000000      1.00   0.000000   0.000000    0.000000       908.0   \n",
       "4  0.000000      0.00   0.000000   0.000000    1.000000         0.0   \n",
       "\n",
       "   max_offset  fold  \n",
       "0        16.0     1  \n",
       "1        38.0     1  \n",
       "2      1032.0     1  \n",
       "3       908.0     1  \n",
       "4         0.0     4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = get_raw_data_dir()\n",
    "\n",
    "if DATA_SOURCE == \"cv\":\n",
    "  EEG_SPECT_PATH = get_processed_data_dir() / \"eeg_spectrograms\" / \"train\" / \"cwt\"\n",
    "  processor = EEGDataProcessor(raw_data_path=DATA_PATH, processed_data_path=get_processed_data_dir())\n",
    "  data_df = processor.process_data(vote_method=DATA_PREPARATION_VOTE_METHOD, skip_parquet=True)\n",
    "\n",
    "  fold_creator = KFoldCreator(n_splits=5, seed=Constants.SEED)\n",
    "  data_df = fold_creator.create_folds(data_df, stratify_col='expert_consensus', group_col='patient_id')\n",
    "else:\n",
    "  EEG_SPECT_PATH = get_processed_data_dir() / \"eeg_spectrograms\" / \"test\" / \"cwt\"\n",
    "  data_df = pd.read_csv(DATA_PATH / \"test.csv\")\n",
    "  create_eeg_spectrograms(EEG_SPECT_PATH, DATA_PATH / \"test_eegs\", data_df)\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_spect_config = {\n",
    "  \"batch_size\": 64,\n",
    "  \"num_workers\": 8,\n",
    "  \"pretrained_model_name\": \"inception_v3\",\n",
    "  \"target_size\": 6,\n",
    "  \"img_size\": (128, 256), \n",
    "  \"dropout_p\": 0.1,\n",
    "  \"image_alignment\": \"stacked\",\n",
    "  \"augmentations\": []\n",
    "}\n",
    "\n",
    "multi_spect_model = BaseCNN(\n",
    "  multi_spect_config[\"pretrained_model_name\"],\n",
    "  pretrained=False,\n",
    "  num_classes=multi_spect_config[\"target_size\"],\n",
    "  dropout_p=multi_spect_config[\"dropout_p\"],\n",
    "  image_alignment=multi_spect_config[\"image_alignment\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_conv_montage_config = {\n",
    "  \"batch_size\": 32,\n",
    "  \"num_workers\": 8,\n",
    "  \"num_nodes\": 19,\n",
    "  \"node_embed_size\": 256,\n",
    "  \"hidden_size\": 256,\n",
    "  \"num_layers\": 1,\n",
    "  \"target_size\": 6,\n",
    "  \"num_cnn_blocks\": 3,\n",
    "  \"dropout\": 0.4,\n",
    "  \"downsample_factor\": 1,\n",
    "  \"use_inception\": True,\n",
    "  \"augmentations\": []\n",
    "}\n",
    "\n",
    "gru_conv_montage_model = NodeAttentionModel(\n",
    "  num_nodes=gru_conv_montage_config[\"num_nodes\"],\n",
    "  node_embed_size=gru_conv_montage_config[\"node_embed_size\"],\n",
    "  hidden_size=gru_conv_montage_config[\"hidden_size\"],\n",
    "  num_layers=gru_conv_montage_config[\"num_layers\"],\n",
    "  num_classes=gru_conv_montage_config[\"target_size\"],\n",
    "  num_cnn_blocks=gru_conv_montage_config[\"num_cnn_blocks\"],\n",
    "  dropout=gru_conv_montage_config[\"dropout\"],\n",
    "  use_inception=gru_conv_montage_config[\"use_inception\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = [\n",
    "  {\n",
    "    \"identifier\": \"multi-spect-cnn\",\n",
    "    \"config\": multi_spect_config,\n",
    "    \"model\": multi_spect_model,\n",
    "    \"model_checkpoints_dir\": get_models_save_path(EXISTING_CHECKPOINT_KAGGLE_DATASET_ID) / \"multi_spec_cnn\" / \"inception_v3\" / DATA_PREPARATION_VOTE_METHOD,\n",
    "    \"autocast_enabled\": False,\n",
    "    \"dataset_creator\": lambda df, mode, augmentations: MultiSpectrogramDataset(\n",
    "      df=df,\n",
    "      targets=Constants.TARGETS,\n",
    "      data_path=DATA_PATH,\n",
    "      img_size=multi_spect_config[\"img_size\"],\n",
    "      eeg_spec_path=EEG_SPECT_PATH,\n",
    "      mode=mode,\n",
    "      apply_augmentations=augmentations\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"identifier\": \"gru_conv_montage\",\n",
    "    \"config\": gru_conv_montage_config,\n",
    "    \"model\": gru_conv_montage_model,\n",
    "    \"model_checkpoints_dir\": get_models_save_path(EXISTING_CHECKPOINT_KAGGLE_DATASET_ID) / \"GRUConvModel\" / DATA_PREPARATION_VOTE_METHOD,\n",
    "    \"autocast_enabled\": device.type == 'cuda',\n",
    "    \"dataset_creator\": lambda df, mode, augmentations: EEGDatasetMontage(\n",
    "      df=df,\n",
    "      data_path=DATA_PATH,\n",
    "      mode=mode,\n",
    "      downsample_factor=gru_conv_montage_config[\"downsample_factor\"],\n",
    "      augmentations=augmentations\n",
    "    )\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_predictions(all_model_predictions):\n",
    "  # simple average ensemble\n",
    "  return np.mean(all_model_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kl_score(true_labels, pred_labels):\n",
    "  kl_loss_fn = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "  return kl_loss_fn(torch.log(pred_labels + 1e-8), true_labels).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ensemble_inference_cv():\n",
    "  \"\"\"Run OOF inference for CV data. Each fold predicts only its validation set\"\"\"\n",
    "  all_model_predictions = []\n",
    "\n",
    "  for config in model_configs:\n",
    "    print(f\"\\n========== Loading {config['identifier']} ==========\")\n",
    "\n",
    "    model_checkpoints_dir = config[\"model_checkpoints_dir\"]\n",
    "    model_paths = [os.path.join(model_checkpoints_dir, f'best_model_fold{i}.pth') for i in range(5)]\n",
    "\n",
    "    # Initialize array to store OOF predictions for this model\n",
    "    model_oof_preds = np.zeros((len(data_df), len(Constants.TARGETS)))\n",
    "    \n",
    "    for fold_idx in range(5):\n",
    "      print(f\"\\n========== Inferencing with Fold {fold_idx} Model ==========\")\n",
    "      model_path = model_paths[fold_idx]\n",
    "      \n",
    "      if not os.path.exists(model_path):\n",
    "          print(f\"Model file not found: {model_path}. Skipping this fold.\")\n",
    "          continue\n",
    "      \n",
    "      # Get validation indices and data for this fold\n",
    "      valid_df = data_df[data_df['fold'] == fold_idx].reset_index(drop=True)\n",
    "      valid_indices = data_df[data_df['fold'] == fold_idx].index.tolist()\n",
    "      \n",
    "      # Create dataset using lambda function\n",
    "      fold_dataset = config['dataset_creator'](valid_df, mode='train', augmentations=config['config']['augmentations'])\n",
    "      \n",
    "      fold_loader = DataLoader(\n",
    "          fold_dataset,\n",
    "          batch_size=config['config']['batch_size'],\n",
    "          shuffle=False,\n",
    "          num_workers=config['config']['num_workers']\n",
    "      )\n",
    "      \n",
    "      # Load model\n",
    "      model = config['model']\n",
    "      model.load_state_dict(torch.load(model_path))\n",
    "      model.to(device)\n",
    "      model.eval()\n",
    "\n",
    "      fold_preds = []\n",
    "      with torch.no_grad():\n",
    "          for x in tqdm(fold_loader, desc=f\"{config['identifier']} Fold {fold_idx}\"):\n",
    "              if isinstance(x, (list, tuple)):\n",
    "                  x = x[0]\n",
    "\n",
    "              x = x.to(device)\n",
    "\n",
    "              with torch.autocast(enabled=config[\"autocast_enabled\"], device_type=device.type):\n",
    "                outputs = model(x)\n",
    "                probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "                fold_preds.append(probs)\n",
    "      \n",
    "      # Store predictions at the correct indices\n",
    "      fold_preds = np.concatenate(fold_preds)\n",
    "      model_oof_preds[valid_indices] = fold_preds\n",
    "      \n",
    "      print(f\"Completed fold {fold_idx} for {config['identifier']}: {fold_preds.shape}\")\n",
    "    \n",
    "    all_model_predictions.append(model_oof_preds)\n",
    "    print(f\"Completed {config['identifier']}: {model_oof_preds.shape}\")\n",
    "\n",
    "  # Simple average across all models\n",
    "  print(\"\\n========== Combining Model Predictions ==========\")\n",
    "  final_predictions = get_ensemble_predictions(all_model_predictions)\n",
    "    \n",
    "  submission = pd.DataFrame({\"eeg_id\": data_df[\"eeg_id\"]})\n",
    "  submission[Constants.TARGETS] = final_predictions\n",
    "\n",
    "  return submission\n",
    "\n",
    "\n",
    "def run_ensemble_inference_test():\n",
    "  \"\"\"Run inference on test data. All folds predict all data, then average\"\"\"\n",
    "  all_model_predictions = []\n",
    "\n",
    "  for config in model_configs:\n",
    "    print(f\"\\n========== Loading {config['identifier']} ==========\")\n",
    "\n",
    "    model_checkpoints_dir = config[\"model_checkpoints_dir\"]\n",
    "    model_paths = [os.path.join(model_checkpoints_dir, f'best_model_fold{i}.pth') for i in range(5)]\n",
    "\n",
    "    dataset = config['dataset_creator'](data_df, mode='test', augmentations=config['config']['augmentations'])\n",
    "    \n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config['config']['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=config['config']['num_workers']\n",
    "    )\n",
    "\n",
    "    # Get predictions from all folds for this model\n",
    "    fold_predictions = []\n",
    "    for i, path in enumerate(model_paths):\n",
    "      print(f\"\\n========== Inferencing with Fold {i} Model ==========\")\n",
    "      if not os.path.exists(path):\n",
    "          print(f\"Model file not found: {path}. Skipping this fold.\")\n",
    "          continue\n",
    "      \n",
    "      model = config['model']\n",
    "      model.load_state_dict(torch.load(path))\n",
    "      model.to(device)\n",
    "      model.eval()\n",
    "\n",
    "      current_fold_preds = []\n",
    "      with torch.no_grad():\n",
    "          for x in tqdm(data_loader, desc=f\"{config['identifier']} Fold {i}\"):\n",
    "              x = x.to(device)\n",
    "\n",
    "              with torch.autocast(enabled=config[\"autocast_enabled\"], device_type=device.type):\n",
    "                outputs = model(x)\n",
    "                probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "                current_fold_preds.append(probs)\n",
    "            \n",
    "      fold_predictions.append(np.concatenate(current_fold_preds))\n",
    "\n",
    "    # Average across folds for this model\n",
    "    model_avg = np.mean(fold_predictions, axis=0)\n",
    "    all_model_predictions.append(model_avg)\n",
    "    print(f\"Completed {config['identifier']}: {model_avg.shape}\")\n",
    "\n",
    "  # Simple average across all models\n",
    "  print(\"\\n========== Combining Model Predictions ==========\")\n",
    "  final_predictions = get_ensemble_predictions(all_model_predictions)\n",
    "    \n",
    "  submission = pd.DataFrame({\"eeg_id\": data_df[\"eeg_id\"]})\n",
    "  submission[Constants.TARGETS] = final_predictions\n",
    "  submission.to_csv(get_submission_csv_path(), index=False)\n",
    "\n",
    "  return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Loading multi-spect-cnn ==========\n",
      "\n",
      "========== Inferencing with Fold 0 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi-spect-cnn Fold 0: 100%|██████████| 64/64 [00:52<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fold 0 for multi-spect-cnn: (4067, 6)\n",
      "\n",
      "========== Inferencing with Fold 1 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi-spect-cnn Fold 1: 100%|██████████| 58/58 [00:44<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fold 1 for multi-spect-cnn: (3658, 6)\n",
      "\n",
      "========== Inferencing with Fold 2 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi-spect-cnn Fold 2: 100%|██████████| 53/53 [00:36<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fold 2 for multi-spect-cnn: (3381, 6)\n",
      "\n",
      "========== Inferencing with Fold 3 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi-spect-cnn Fold 3: 100%|██████████| 42/42 [00:40<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fold 3 for multi-spect-cnn: (2625, 6)\n",
      "\n",
      "========== Inferencing with Fold 4 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi-spect-cnn Fold 4: 100%|██████████| 53/53 [00:48<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fold 4 for multi-spect-cnn: (3358, 6)\n",
      "Completed multi-spect-cnn: (17089, 6)\n",
      "\n",
      "========== Loading gru_conv_montage ==========\n",
      "\n",
      "========== Inferencing with Fold 0 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gru_conv_montage Fold 0: 100%|██████████| 128/128 [00:45<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fold 0 for gru_conv_montage: (4067, 6)\n",
      "\n",
      "========== Inferencing with Fold 1 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gru_conv_montage Fold 1: 100%|██████████| 115/115 [00:31<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fold 1 for gru_conv_montage: (3658, 6)\n",
      "\n",
      "========== Inferencing with Fold 2 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gru_conv_montage Fold 2: 100%|██████████| 106/106 [00:33<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fold 2 for gru_conv_montage: (3381, 6)\n",
      "\n",
      "========== Inferencing with Fold 3 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gru_conv_montage Fold 3: 100%|██████████| 83/83 [00:44<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fold 3 for gru_conv_montage: (2625, 6)\n",
      "\n",
      "========== Inferencing with Fold 4 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gru_conv_montage Fold 4: 100%|██████████| 105/105 [01:00<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fold 4 for gru_conv_montage: (3358, 6)\n",
      "Completed gru_conv_montage: (17089, 6)\n",
      "\n",
      "========== Combining Model Predictions ==========\n"
     ]
    }
   ],
   "source": [
    "if DATA_SOURCE == \"cv\":\n",
    "  submission = run_ensemble_inference_cv()\n",
    "else:\n",
    "  submission = run_ensemble_inference_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence Score on CV Data: 0.5512837767601013\n"
     ]
    }
   ],
   "source": [
    "# calculate KL divergence score if using cv data\n",
    "if DATA_SOURCE == \"cv\":\n",
    "  true_labels = torch.tensor(data_df[Constants.TARGETS].values, dtype=torch.float32)\n",
    "  pred_labels = torch.tensor(submission[Constants.TARGETS].values, dtype=torch.float32)\n",
    "  kl_score = calculate_kl_score(true_labels, pred_labels)\n",
    "  print(f\"KL Divergence Score on CV Data: {kl_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
