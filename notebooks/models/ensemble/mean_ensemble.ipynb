{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXISTING_CHECKPOINT_KAGGLE_DATASET_ID = \"hsm-models\"\n",
    "DATA_PREPARATION_VOTE_METHOD = \"max_vote_window\" # \"max_vote_window\" or \"sum_and_normalize\". Decides how to aggregate the predictions of the overlapping windows\n",
    "DATA_SOURCE = \"cv\" # \"cv\" or \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "if bool(os.environ.get(\"KAGGLE_URL_BASE\", \"\")):\n",
    "  import sys\n",
    "  # running on kaggle\n",
    "  sys.path.insert(0, \"/kaggle/input/hsm-source-files\")\n",
    "else:\n",
    "  # running locally\n",
    "  sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"..\")))\n",
    "\n",
    "from src.utils.utils import get_raw_data_dir, get_processed_data_dir, get_submission_csv_path, get_models_save_path, set_seeds\n",
    "from src.utils.constants import Constants\n",
    "\n",
    "from src.datasets.multi_spectrogram import MultiSpectrogramDataset\n",
    "from src.datasets.eeg_dataset_montage import EEGDatasetMontage\n",
    "from src.models.base_cnn import BaseCNN\n",
    "from src.models.gru_convolution_attention import NodeAttentionModel\n",
    "from src.utils.eeg_spectrogram_creator import EEGSpectrogramGenerator\n",
    "from src.datasets.eeg_processor import EEGDataProcessor\n",
    "\n",
    "set_seeds(Constants.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eeg_spectrograms(eeg_spectrograms_path, raw_eegs_path, data_df):\n",
    "  os.makedirs(eeg_spectrograms_path, exist_ok=True)\n",
    "  existing_specs = len(list(eeg_spectrograms_path.glob(\"*.npy\")))\n",
    "\n",
    "  eeg_ids = data_df[\"eeg_id\"].unique()\n",
    "  if existing_specs >= len(eeg_ids):\n",
    "    print(\"EEG Spectrograms already created.\")\n",
    "    return\n",
    "  else:\n",
    "    spectrogram_creator = EEGSpectrogramGenerator([\"cwt\"])\n",
    "    for eeg_id in tqdm(eeg_ids, desc=\"Generating EEG Spectrograms\"):\n",
    "        eeg_path = os.path.join(raw_eegs_path, f\"{eeg_id}.parquet\")\n",
    "        eeg = pd.read_parquet(eeg_path)\n",
    "        spectrograms = spectrogram_creator.generate(eeg)\n",
    "        np.save(eeg_spectrograms_path / f\"{eeg_id}.npy\", spectrograms['cwt']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor initialized.\n",
      "Raw data path: '/home/david/git/aicomp/data'\n",
      "Processed data path: '/home/david/git/aicomp/data/processed'\n",
      "==================================================\n",
      "Starting EEG Data Processing Pipeline\n",
      "==================================================\n",
      "Skipping Parquet file creation as requested.\n",
      "Using 'max_vote_window' vote aggregation strategy.\n",
      "\n",
      "Processed train data saved to '/home/david/git/aicomp/data/processed/train_processed.csv'.\n",
      "Shape of the final dataframe: (17089, 12)\n",
      "\n",
      "Pipeline finished successfully!\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>expert_consensus</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "      <th>min_offset</th>\n",
       "      <th>max_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>568657</td>\n",
       "      <td>789577333</td>\n",
       "      <td>20654</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>582999</td>\n",
       "      <td>1552638400</td>\n",
       "      <td>20230</td>\n",
       "      <td>LPD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642382</td>\n",
       "      <td>14960202</td>\n",
       "      <td>5955</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>751790</td>\n",
       "      <td>618728447</td>\n",
       "      <td>38549</td>\n",
       "      <td>GPD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>908.0</td>\n",
       "      <td>908.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>778705</td>\n",
       "      <td>52296320</td>\n",
       "      <td>40955</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eeg_id  spectrogram_id  patient_id expert_consensus  seizure_vote  \\\n",
       "0  568657       789577333       20654            Other           0.0   \n",
       "1  582999      1552638400       20230              LPD           0.0   \n",
       "2  642382        14960202        5955            Other           0.0   \n",
       "3  751790       618728447       38549              GPD           0.0   \n",
       "4  778705        52296320       40955            Other           0.0   \n",
       "\n",
       "   lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote  min_offset  \\\n",
       "0  0.000000      0.25   0.000000   0.166667    0.583333         0.0   \n",
       "1  0.857143      0.00   0.071429   0.000000    0.071429         0.0   \n",
       "2  0.000000      0.00   0.000000   0.000000    1.000000      1008.0   \n",
       "3  0.000000      1.00   0.000000   0.000000    0.000000       908.0   \n",
       "4  0.000000      0.00   0.000000   0.000000    1.000000         0.0   \n",
       "\n",
       "   max_offset  \n",
       "0        16.0  \n",
       "1        38.0  \n",
       "2      1032.0  \n",
       "3       908.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = get_raw_data_dir()\n",
    "\n",
    "if DATA_SOURCE == \"cv\":\n",
    "  EEG_SPECT_PATH = get_processed_data_dir() / \"eeg_spectrograms\" / \"train\" / \"cwt\"\n",
    "  processor = EEGDataProcessor(raw_data_path=DATA_PATH, processed_data_path=get_processed_data_dir())\n",
    "  data_df = processor.process_data(vote_method=DATA_PREPARATION_VOTE_METHOD, skip_parquet=True)\n",
    "else:\n",
    "  EEG_SPECT_PATH = get_processed_data_dir() / \"eeg_spectrograms\" / \"test\" / \"cwt\"\n",
    "  data_df = pd.read_csv(DATA_PATH / \"test.csv\")\n",
    "  create_eeg_spectrograms(EEG_SPECT_PATH, DATA_PATH / \"test_eegs\", data_df)\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_spect_config = {\n",
    "      \"batch_size\": 64,\n",
    "      \"num_workers\": 8,\n",
    "      \"pretrained_model_name\": \"inception_v3\",\n",
    "      \"target_size\": 6,\n",
    "      \"img_size\": (128, 256), \n",
    "      \"dropout_p\": 0.1,\n",
    "      \"image_alignment\": \"stacked\",\n",
    "      \"augmentations\": []\n",
    "}\n",
    "\n",
    "multi_spect_dataset = test_dataset = MultiSpectrogramDataset(\n",
    "  df=data_df, \n",
    "  targets=Constants.TARGETS, \n",
    "  data_path=DATA_PATH, \n",
    "  img_size=multi_spect_config[\"img_size\"], \n",
    "  eeg_spec_path=EEG_SPECT_PATH, \n",
    "  mode='test' if DATA_SOURCE == \"test\" else 'train',\n",
    "  apply_augmentations=multi_spect_config[\"augmentations\"],\n",
    ")\n",
    "\n",
    "multi_spect_model = BaseCNN(\n",
    "  multi_spect_config[\"pretrained_model_name\"],\n",
    "  pretrained=False,\n",
    "  num_classes=multi_spect_config[\"target_size\"],\n",
    "  dropout_p=multi_spect_config[\"dropout_p\"],\n",
    "  image_alignment=multi_spect_config[\"image_alignment\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_conv_montage_config = {\n",
    "  \"batch_size\": 32,\n",
    "  \"num_workers\": 8,\n",
    "  \"num_nodes\": 20,\n",
    "  \"node_embed_size\": 256,\n",
    "  \"hidden_size\": 256,\n",
    "  \"num_layers\": 1,\n",
    "  \"target_size\": 6,\n",
    "  \"num_cnn_blocks\": 3,\n",
    "  \"dropout\": 0.4,\n",
    "  \"downsample_factor\": 4,\n",
    "  \"augmentations\": []\n",
    "}\n",
    "\n",
    "gru_conv_montage_dataset = EEGDatasetMontage(\n",
    "  df=data_df,\n",
    "  data_path=DATA_PATH,\n",
    "  mode='test' if DATA_SOURCE == \"test\" else 'val',\n",
    "  downsample_factor=gru_conv_montage_config[\"downsample_factor\"],\n",
    "  augmentations=gru_conv_montage_config[\"augmentations\"]\n",
    "  )\n",
    "\n",
    "gru_conv_montage_model = NodeAttentionModel(\n",
    "  num_nodes=gru_conv_montage_config[\"num_nodes\"],\n",
    "  node_embed_size=gru_conv_montage_config[\"node_embed_size\"],\n",
    "  hidden_size=gru_conv_montage_config[\"hidden_size\"],\n",
    "  num_layers=gru_conv_montage_config[\"num_layers\"],\n",
    "  num_classes=gru_conv_montage_config[\"target_size\"],\n",
    "  num_cnn_blocks=gru_conv_montage_config[\"num_cnn_blocks\"],\n",
    "  dropout=gru_conv_montage_config[\"dropout\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = [\n",
    "  {\n",
    "    \"identifier\": \"multi-spect-cnn\",\n",
    "    \"config\": multi_spect_config,\n",
    "    \"dataloader\": DataLoader(multi_spect_dataset, batch_size=multi_spect_config[\"batch_size\"], shuffle=False, num_workers=multi_spect_config[\"num_workers\"]),\n",
    "    \"model\": multi_spect_model,\n",
    "    \"model_checkpoints_dir\": get_models_save_path(EXISTING_CHECKPOINT_KAGGLE_DATASET_ID) / \"multi_spec_cnn\" / \"inception_v3\" / DATA_PREPARATION_VOTE_METHOD,\n",
    "\n",
    "  },\n",
    "  # {\n",
    "  #   \"identifier\": \"gru_conv_montage\",\n",
    "  #   \"config\": gru_conv_montage_config,\n",
    "  #   \"dataloader\": DataLoader(gru_conv_montage_dataset, batch_size=gru_conv_montage_config[\"batch_size\"], shuffle=False, num_workers=gru_conv_montage_config[\"num_workers\"]),\n",
    "  #   \"model\": gru_conv_montage_model,\n",
    "  #   \"model_checkpoints_dir\": get_models_save_path(EXISTING_CHECKPOINT_KAGGLE_DATASET_ID) / \"multi_spec_cnn\" / \"inception_v3\" / DATA_PREPARATION_VOTE_METHOD,\n",
    "  # }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_score(all_model_predictions):\n",
    "  # simple average ensemble\n",
    "  return np.mean(all_model_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ensemble_inference():\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  print(f\"Using device: {device}\")\n",
    "\n",
    "  all_model_predictions = []  # Store predictions from each model architecture\n",
    "\n",
    "  for config in model_configs:\n",
    "    print(f\"\\n========== Loading {config['identifier']} ==========\")\n",
    "\n",
    "    model_checkpoints_dir = config[\"model_checkpoints_dir\"]\n",
    "    model_paths = [os.path.join(model_checkpoints_dir, f'best_model_fold{i}.pth') for i in range(5)]\n",
    "    data_loader = config[\"dataloader\"]\n",
    "\n",
    "    # Get predictions from all folds for this model\n",
    "    fold_predictions = []\n",
    "    for i, path in enumerate(model_paths):\n",
    "      print(f\"\\n========== Inferencing with Fold {i} Model ==========\")\n",
    "      if not os.path.exists(path):\n",
    "          print(f\"Model file not found: {path}. Skipping this fold.\")\n",
    "          continue\n",
    "      \n",
    "      model = config['model']\n",
    "      model.load_state_dict(torch.load(path, map_location=device))\n",
    "      model.to(device)\n",
    "      model.eval()\n",
    "\n",
    "      current_fold_preds = []\n",
    "      with torch.no_grad():\n",
    "          for x in tqdm(data_loader, desc=f\"{config['identifier']} Fold {i}\"):\n",
    "              # if the dataloader returns a tuple (inputs, targets), unpack it\n",
    "              if isinstance(x, (list, tuple)):\n",
    "                  x = x[0]\n",
    "\n",
    "              x = x.to(device)\n",
    "              outputs = model(x)\n",
    "              probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "              current_fold_preds.append(probs)\n",
    "            \n",
    "      fold_predictions.append(np.concatenate(current_fold_preds))\n",
    "\n",
    "      # Average across folds for this model\n",
    "      model_avg = np.mean(fold_predictions, axis=0)\n",
    "      all_model_predictions.append(model_avg)\n",
    "      print(f\"Completed {config['identifier']}: {model_avg.shape}\")\n",
    "\n",
    "  # Simple average across all models\n",
    "  print(\"\\n========== Combining Model Predictions ==========\")\n",
    "  final_predictions = get_ensemble_score(all_model_predictions)\n",
    "    \n",
    "  submission = pd.DataFrame({\"eeg_id\": data_df[\"eeg_id\"]})\n",
    "  submission[Constants.TARGETS] = final_predictions\n",
    "  submission.to_csv(get_submission_csv_path(), index=False)\n",
    "\n",
    "  return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "========== Loading multi-spect-cnn ==========\n",
      "\n",
      "========== Inferencing with Fold 0 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi-spect-cnn Fold 0: 100%|██████████| 268/268 [02:21<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed multi-spect-cnn: (17089, 6)\n",
      "\n",
      "========== Inferencing with Fold 1 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi-spect-cnn Fold 1: 100%|██████████| 268/268 [02:20<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed multi-spect-cnn: (17089, 6)\n",
      "\n",
      "========== Inferencing with Fold 2 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi-spect-cnn Fold 2: 100%|██████████| 268/268 [02:16<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed multi-spect-cnn: (17089, 6)\n",
      "\n",
      "========== Inferencing with Fold 3 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi-spect-cnn Fold 3: 100%|██████████| 268/268 [02:18<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed multi-spect-cnn: (17089, 6)\n",
      "\n",
      "========== Inferencing with Fold 4 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi-spect-cnn Fold 4: 100%|██████████| 268/268 [02:18<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed multi-spect-cnn: (17089, 6)\n",
      "\n",
      "========== Combining Model Predictions ==========\n"
     ]
    }
   ],
   "source": [
    "submission = run_ensemble_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence Score on CV Data: 0.42844244837760925\n"
     ]
    }
   ],
   "source": [
    "# calculate KL divergence score if using cv data\n",
    "if DATA_SOURCE == \"cv\":\n",
    "  kl_loss_fn = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "  true_labels = torch.tensor(data_df[Constants.TARGETS].values, dtype=torch.float32)\n",
    "  pred_labels = torch.tensor(submission[Constants.TARGETS].values, dtype=torch.float32)\n",
    "  kl_score = kl_loss_fn(torch.log(pred_labels + 1e-8), true_labels).item()\n",
    "  print(f\"KL Divergence Score on CV Data: {kl_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
