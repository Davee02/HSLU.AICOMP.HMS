{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXISTING_CHECKPOINT_KAGGLE_DATASET_ID = \"hsm-models\"\n",
    "DATA_PREPARATION_VOTE_METHOD = \"max_vote_window\" # \"max_vote_window\" or \"sum_and_normalize\". Decides how to aggregate the predictions of the overlapping windows\n",
    "DATA_SOURCE = \"cv\" # \"cv\" or \"test\". On Kaggle, this is autpmatically set to \"test\"\n",
    "WEIGHTS = [0.23, 0.77] # Pre-computed weights for each model in the ensemble. For CV, the weights are always computed automatically. For test, they must be provided here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "if bool(os.environ.get(\"KAGGLE_URL_BASE\", \"\")):\n",
    "  import sys\n",
    "  # running on kaggle\n",
    "  sys.path.insert(0, \"/kaggle/input/hsm-source-files\")\n",
    "else:\n",
    "  # running locally\n",
    "  sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"..\")))\n",
    "\n",
    "from src.utils.utils import get_raw_data_dir, get_processed_data_dir, get_submission_csv_path, get_models_save_path, set_seeds, running_in_kaggle\n",
    "from src.utils.constants import Constants\n",
    "\n",
    "from src.utils.k_folds_creator import KFoldCreator\n",
    "from src.datasets.multi_spectrogram import MultiSpectrogramDataset\n",
    "from src.datasets.eeg_dataset_montage import EEGDatasetMontage\n",
    "from src.models.base_cnn import BaseCNN\n",
    "from src.models.gru_convolution_attention import NodeAttentionModel\n",
    "from src.utils.eeg_spectrogram_creator import EEGSpectrogramGenerator\n",
    "from src.datasets.eeg_processor import EEGDataProcessor\n",
    "\n",
    "set_seeds(Constants.SEED)\n",
    "\n",
    "if running_in_kaggle():\n",
    "  DATA_SOURCE = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eeg_spectrograms(eeg_spectrograms_path, raw_eegs_path, data_df):\n",
    "  os.makedirs(eeg_spectrograms_path, exist_ok=True)\n",
    "  existing_specs = len(list(eeg_spectrograms_path.glob(\"*.npy\")))\n",
    "\n",
    "  eeg_ids = data_df[\"eeg_id\"].unique()\n",
    "  if existing_specs >= len(eeg_ids):\n",
    "    print(\"EEG Spectrograms already created.\")\n",
    "    return\n",
    "  else:\n",
    "    spectrogram_creator = EEGSpectrogramGenerator([\"cwt\"])\n",
    "    for eeg_id in tqdm(eeg_ids, desc=\"Generating EEG Spectrograms\"):\n",
    "        eeg_path = os.path.join(raw_eegs_path, f\"{eeg_id}.parquet\")\n",
    "        eeg = pd.read_parquet(eeg_path)\n",
    "        spectrograms = spectrogram_creator.generate(eeg)\n",
    "        np.save(eeg_spectrograms_path / f\"{eeg_id}.npy\", spectrograms['cwt']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG Spectrograms already created.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>853520</td>\n",
       "      <td>3911565283</td>\n",
       "      <td>6885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spectrogram_id      eeg_id  patient_id\n",
       "0          853520  3911565283        6885"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = get_raw_data_dir()\n",
    "\n",
    "if DATA_SOURCE == \"cv\":\n",
    "  EEG_SPECT_PATH = get_processed_data_dir() / \"eeg_spectrograms\" / \"train\" / \"cwt\"\n",
    "  processor = EEGDataProcessor(raw_data_path=DATA_PATH, processed_data_path=get_processed_data_dir())\n",
    "  data_df = processor.process_data(vote_method=DATA_PREPARATION_VOTE_METHOD, skip_parquet=True)\n",
    "\n",
    "  fold_creator = KFoldCreator(n_splits=5, seed=Constants.SEED)\n",
    "  data_df = fold_creator.create_folds(data_df, stratify_col='expert_consensus', group_col='patient_id')\n",
    "else:\n",
    "  EEG_SPECT_PATH = get_processed_data_dir() / \"eeg_spectrograms\" / \"test\" / \"cwt\"\n",
    "  data_df = pd.read_csv(DATA_PATH / \"test.csv\")\n",
    "  create_eeg_spectrograms(EEG_SPECT_PATH, DATA_PATH / \"test_eegs\", data_df)\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_spect_config = {\n",
    "  \"batch_size\": 64,\n",
    "  \"num_workers\": 8,\n",
    "  \"pretrained_model_name\": \"inception_v3\",\n",
    "  \"target_size\": 6,\n",
    "  \"img_size\": (128, 256), \n",
    "  \"dropout_p\": 0.1,\n",
    "  \"image_alignment\": \"stacked\",\n",
    "  \"augmentations\": []\n",
    "}\n",
    "\n",
    "multi_spect_model = BaseCNN(\n",
    "  multi_spect_config[\"pretrained_model_name\"],\n",
    "  pretrained=False,\n",
    "  num_classes=multi_spect_config[\"target_size\"],\n",
    "  dropout_p=multi_spect_config[\"dropout_p\"],\n",
    "  image_alignment=multi_spect_config[\"image_alignment\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_conv_montage_config = {\n",
    "  \"batch_size\": 32,\n",
    "  \"num_workers\": 8,\n",
    "  \"num_nodes\": 19,\n",
    "  \"node_embed_size\": 256,\n",
    "  \"hidden_size\": 256,\n",
    "  \"num_layers\": 1,\n",
    "  \"target_size\": 6,\n",
    "  \"num_cnn_blocks\": 3,\n",
    "  \"dropout\": 0.4,\n",
    "  \"downsample_factor\": 1,\n",
    "  \"use_inception\": True,\n",
    "  \"augmentations\": []\n",
    "}\n",
    "\n",
    "gru_conv_montage_model = NodeAttentionModel(\n",
    "  num_nodes=gru_conv_montage_config[\"num_nodes\"],\n",
    "  node_embed_size=gru_conv_montage_config[\"node_embed_size\"],\n",
    "  hidden_size=gru_conv_montage_config[\"hidden_size\"],\n",
    "  num_layers=gru_conv_montage_config[\"num_layers\"],\n",
    "  num_classes=gru_conv_montage_config[\"target_size\"],\n",
    "  num_cnn_blocks=gru_conv_montage_config[\"num_cnn_blocks\"],\n",
    "  dropout=gru_conv_montage_config[\"dropout\"],\n",
    "  use_inception=gru_conv_montage_config[\"use_inception\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = [\n",
    "  {\n",
    "    \"identifier\": \"multi-spect-cnn\",\n",
    "    \"config\": multi_spect_config,\n",
    "    \"model\": multi_spect_model,\n",
    "    \"model_checkpoints_dir\": get_models_save_path(EXISTING_CHECKPOINT_KAGGLE_DATASET_ID) / \"multi_spec_cnn\" / \"inception_v3\" / DATA_PREPARATION_VOTE_METHOD,\n",
    "    \"autocast_enabled\": False,\n",
    "    \"dataset_creator\": lambda df, mode, augmentations: MultiSpectrogramDataset(\n",
    "      df=df,\n",
    "      targets=Constants.TARGETS,\n",
    "      data_path=DATA_PATH,\n",
    "      img_size=multi_spect_config[\"img_size\"],\n",
    "      eeg_spec_path=EEG_SPECT_PATH,\n",
    "      mode=mode,\n",
    "      apply_augmentations=augmentations\n",
    "    )\n",
    "  },\n",
    "  {\n",
    "    \"identifier\": \"gru_conv_montage\",\n",
    "    \"config\": gru_conv_montage_config,\n",
    "    \"model\": gru_conv_montage_model,\n",
    "    \"model_checkpoints_dir\": get_models_save_path(EXISTING_CHECKPOINT_KAGGLE_DATASET_ID) / \"GRUConvModel\" / DATA_PREPARATION_VOTE_METHOD,\n",
    "    \"autocast_enabled\": device.type == 'cuda',\n",
    "    \"dataset_creator\": lambda df, mode, augmentations: EEGDatasetMontage(\n",
    "      df=df,\n",
    "      data_path=DATA_PATH,\n",
    "      mode=mode,\n",
    "      downsample_factor=gru_conv_montage_config[\"downsample_factor\"],\n",
    "      augmentations=augmentations\n",
    "    )\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_predictions(all_model_predictions, weights):\n",
    "    # Returns weighted average of predictions\n",
    "    weights = np.array(weights) / np.sum(weights) # normalize weights to sum to 1\n",
    "    ensemble_pred = np.zeros_like(all_model_predictions[0])\n",
    "    for i, preds in enumerate(all_model_predictions):\n",
    "        ensemble_pred += weights[i] * preds\n",
    "    return ensemble_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kl_score(true_labels, pred_labels):\n",
    "  kl_loss_fn = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "  return kl_loss_fn(torch.log(pred_labels + 1e-8), true_labels).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_ensemble_weights(all_model_predictions, true_labels, method, max_iterations):\n",
    "    n_models = len(all_model_predictions)\n",
    "    \n",
    "    def objective(weights):\n",
    "        # Weighted average of predictions\n",
    "        ensemble_pred = get_ensemble_predictions(all_model_predictions, weights)\n",
    "        \n",
    "        # Calculate KL divergence\n",
    "        pred_tensor = torch.tensor(ensemble_pred, dtype=torch.float32)\n",
    "        true_tensor = torch.tensor(true_labels, dtype=torch.float32)\n",
    "        return calculate_kl_score(true_tensor, pred_tensor)\n",
    "\n",
    "    # Initial weights (equal for all models)\n",
    "    initial_weights = np.ones(n_models) / n_models\n",
    "    \n",
    "    # Bounds: each weight between 0 and 1\n",
    "    bounds = [(0, 1) for _ in range(n_models)]\n",
    "    \n",
    "    # Optimize\n",
    "    print(f\"Optimizing weights for {n_models} models...\")\n",
    "    print(f\"Initial equal weights: {initial_weights}\")\n",
    "    print(f\"Initial KL score: {objective(initial_weights):.6f}\")\n",
    "    \n",
    "    result = minimize(\n",
    "        objective,\n",
    "        initial_weights,\n",
    "        method=method,\n",
    "        bounds=bounds,\n",
    "        options={\"maxiter\": max_iterations}\n",
    "    )\n",
    "    \n",
    "    print(result)\n",
    "\n",
    "    optimal_weights = result.x / result.x.sum()  # Normalize weights to sum to 1\n",
    "    best_score = result.fun\n",
    "    \n",
    "    print(f\"Optimized weights: {optimal_weights}\")\n",
    "    print(f\"Optimized KL score: {best_score:.6f}\")\n",
    "    print(f\"Improvement: {objective(initial_weights) - best_score:.6f}\")\n",
    "    \n",
    "    return optimal_weights, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_weights(all_model_predictions, true_labels, n_steps=500):\n",
    "    \"\"\"Brute force grid search for 2 models\"\"\"\n",
    "    n_models = len(all_model_predictions)\n",
    "    \n",
    "    if n_models != 2:\n",
    "        raise ValueError(\"Grid search only implemented for 2 models\")\n",
    "    \n",
    "    best_score = float('inf')\n",
    "    best_weights = None\n",
    "    \n",
    "    print(f\"Grid searching with {n_steps} steps...\")\n",
    "    \n",
    "    for i in range(n_steps + 1):\n",
    "        w1 = i / n_steps\n",
    "        w2 = 1 - w1\n",
    "        weights = np.array([w1, w2])\n",
    "        \n",
    "        ensemble_pred = get_ensemble_predictions(all_model_predictions, weights)\n",
    "        pred_tensor = torch.tensor(ensemble_pred, dtype=torch.float32)\n",
    "        true_tensor = torch.tensor(true_labels, dtype=torch.float32)\n",
    "        score = calculate_kl_score(true_tensor, pred_tensor)\n",
    "        \n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_weights = weights\n",
    "            print(f\"New best - Weights: [{w1:.2f}, {w2:.2f}], Score: {score:.6f}\")\n",
    "    \n",
    "    print(f\"\\nBest weights: {best_weights}\")\n",
    "    print(f\"Best score: {best_score:.6f}\")\n",
    "    \n",
    "    return best_weights, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ensemble_inference_cv():\n",
    "  \"\"\"Run OOF inference for CV data. Each fold predicts only its validation set\"\"\"\n",
    "  all_model_predictions = []\n",
    "\n",
    "  for config in model_configs:\n",
    "    print(f\"\\n========== Loading {config['identifier']} ==========\")\n",
    "\n",
    "    model_checkpoints_dir = config[\"model_checkpoints_dir\"]\n",
    "    model_paths = [os.path.join(model_checkpoints_dir, f'best_model_fold{i}.pth') for i in range(5)]\n",
    "\n",
    "    # Initialize array to store OOF predictions for this model\n",
    "    model_oof_preds = np.zeros((len(data_df), len(Constants.TARGETS)))\n",
    "    \n",
    "    for fold_idx in range(5):\n",
    "      print(f\"\\n========== Inferencing with Fold {fold_idx} Model ==========\")\n",
    "      model_path = model_paths[fold_idx]\n",
    "      \n",
    "      if not os.path.exists(model_path):\n",
    "          print(f\"Model file not found: {model_path}. Skipping this fold.\")\n",
    "          continue\n",
    "      \n",
    "      # Get validation indices and data for this fold\n",
    "      valid_df = data_df[data_df['fold'] == fold_idx].reset_index(drop=True)\n",
    "      valid_indices = data_df[data_df['fold'] == fold_idx].index.tolist()\n",
    "      \n",
    "      # Create dataset using lambda function\n",
    "      fold_dataset = config['dataset_creator'](valid_df, mode='train', augmentations=config['config']['augmentations'])\n",
    "      \n",
    "      fold_loader = DataLoader(\n",
    "          fold_dataset,\n",
    "          batch_size=config['config']['batch_size'],\n",
    "          shuffle=False,\n",
    "          num_workers=config['config']['num_workers']\n",
    "      )\n",
    "      \n",
    "      # Load model\n",
    "      model = config['model']\n",
    "      model.load_state_dict(torch.load(model_path))\n",
    "      model.to(device)\n",
    "      model.eval()\n",
    "\n",
    "      fold_preds = []\n",
    "      with torch.no_grad():\n",
    "          for x in tqdm(fold_loader, desc=f\"{config['identifier']} Fold {fold_idx}\"):\n",
    "              if isinstance(x, (list, tuple)):\n",
    "                  x = x[0]\n",
    "\n",
    "              x = x.to(device)\n",
    "\n",
    "              with torch.autocast(enabled=config[\"autocast_enabled\"], device_type=device.type):\n",
    "                outputs = model(x)\n",
    "                probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "                fold_preds.append(probs)\n",
    "      \n",
    "      # Store predictions at the correct indices\n",
    "      fold_preds = np.concatenate(fold_preds)\n",
    "      model_oof_preds[valid_indices] = fold_preds\n",
    "      \n",
    "      print(f\"Completed fold {fold_idx} for {config['identifier']}: {fold_preds.shape}\")\n",
    "    \n",
    "    all_model_predictions.append(model_oof_preds)\n",
    "    print(f\"Completed {config['identifier']}: {model_oof_preds.shape}\")\n",
    "\n",
    "  true_labels = data_df[Constants.TARGETS].values\n",
    "  optimal_weights, _ = grid_search_weights(\n",
    "      all_model_predictions, \n",
    "      true_labels,\n",
    "      n_steps=100\n",
    "  )\n",
    "\n",
    "  # Simple average across all models\n",
    "  print(\"\\n========== Combining Model Predictions ==========\")\n",
    "  final_predictions = get_ensemble_predictions(all_model_predictions, weights=optimal_weights)\n",
    "\n",
    "  submission = pd.DataFrame({\"eeg_id\": data_df[\"eeg_id\"]})\n",
    "  submission[Constants.TARGETS] = final_predictions\n",
    "\n",
    "  return submission, all_model_predictions\n",
    "\n",
    "\n",
    "def run_ensemble_inference_test(weights):\n",
    "  \"\"\"Run inference on test data with optional pre-computed weights\"\"\"\n",
    "  assert weights is not None or len(weights) == 0, \"Weights must be provided for test inference\"\n",
    "\n",
    "  all_model_predictions = []\n",
    "\n",
    "  for config in model_configs:\n",
    "    print(f\"\\n========== Loading {config['identifier']} ==========\")\n",
    "\n",
    "    model_checkpoints_dir = config[\"model_checkpoints_dir\"]\n",
    "    model_paths = [os.path.join(model_checkpoints_dir, f'best_model_fold{i}.pth') for i in range(5)]\n",
    "\n",
    "    dataset = config['dataset_creator'](data_df, mode='test', augmentations=config['config']['augmentations'])\n",
    "    \n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=config['config']['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=config['config']['num_workers']\n",
    "    )\n",
    "\n",
    "    # Get predictions from all folds for this model\n",
    "    fold_predictions = []\n",
    "    for i, path in enumerate(model_paths):\n",
    "      print(f\"\\n========== Inferencing with Fold {i} Model ==========\")\n",
    "      if not os.path.exists(path):\n",
    "          print(f\"Model file not found: {path}. Skipping this fold.\")\n",
    "          continue\n",
    "      \n",
    "      model = config['model']\n",
    "      model.load_state_dict(torch.load(path))\n",
    "      model.to(device)\n",
    "      model.eval()\n",
    "\n",
    "      current_fold_preds = []\n",
    "      with torch.no_grad():\n",
    "          for x in tqdm(data_loader, desc=f\"{config['identifier']} Fold {i}\"):\n",
    "              x = x.to(device)\n",
    "\n",
    "              with torch.autocast(enabled=config[\"autocast_enabled\"], device_type=device.type):\n",
    "                outputs = model(x)\n",
    "                probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "                current_fold_preds.append(probs)\n",
    "            \n",
    "      fold_predictions.append(np.concatenate(current_fold_preds))\n",
    "\n",
    "    # Average across folds for this model\n",
    "    model_avg = np.mean(fold_predictions, axis=0)\n",
    "    all_model_predictions.append(model_avg)\n",
    "    print(f\"Completed {config['identifier']}: {model_avg.shape}\")\n",
    "\n",
    "  # Calculate weighted mean across all models\n",
    "  print(\"\\n========== Combining Model Predictions ==========\")\n",
    "  final_predictions = get_ensemble_predictions(all_model_predictions, weights)\n",
    "    \n",
    "  submission = pd.DataFrame({\"eeg_id\": data_df[\"eeg_id\"]})\n",
    "  submission[Constants.TARGETS] = final_predictions\n",
    "  submission.to_csv(get_submission_csv_path(), index=False)\n",
    "\n",
    "  return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Loading multi-spect-cnn ==========\n",
      "\n",
      "========== Inferencing with Fold 0 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi-spect-cnn Fold 0: 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Inferencing with Fold 1 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi-spect-cnn Fold 1: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Inferencing with Fold 2 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi-spect-cnn Fold 2: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Inferencing with Fold 3 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi-spect-cnn Fold 3: 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Inferencing with Fold 4 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "multi-spect-cnn Fold 4: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed multi-spect-cnn: (1, 6)\n",
      "\n",
      "========== Loading gru_conv_montage ==========\n",
      "\n",
      "========== Inferencing with Fold 0 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gru_conv_montage Fold 0: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Inferencing with Fold 1 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gru_conv_montage Fold 1: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Inferencing with Fold 2 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gru_conv_montage Fold 2: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Inferencing with Fold 3 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gru_conv_montage Fold 3: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Inferencing with Fold 4 Model ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gru_conv_montage Fold 4: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed gru_conv_montage: (1, 6)\n",
      "\n",
      "========== Combining Model Predictions ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if DATA_SOURCE == \"cv\":\n",
    "  submission, all_model_predictions = run_ensemble_inference_cv()\n",
    "else:\n",
    "  submission = run_ensemble_inference_test(WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_labels = data_df[Constants.TARGETS].values\n",
    "\n",
    "# # optimal_weights, _ = optimize_ensemble_weights(\n",
    "# #     all_model_predictions, \n",
    "# #     true_labels,\n",
    "# #     method=\"SLSQP\",\n",
    "# #     max_iterations=100\n",
    "# # )\n",
    "\n",
    "# optimal_weights, _ = grid_search_weights(\n",
    "#     all_model_predictions, \n",
    "#     true_labels,\n",
    "#     n_steps=100\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate KL divergence score if using cv data\n",
    "if DATA_SOURCE == \"cv\":\n",
    "  true_labels = torch.tensor(data_df[Constants.TARGETS].values, dtype=torch.float32)\n",
    "  pred_labels = torch.tensor(submission[Constants.TARGETS].values, dtype=torch.float32)\n",
    "  kl_score = calculate_kl_score(true_labels, pred_labels)\n",
    "  print(f\"KL Divergence Score on CV Data: {kl_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
