{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2dedbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 21:21:28,096 :: root :: INFO :: Initialising Utils\n",
      "2025-11-02 21:21:28,139 :: root :: INFO :: Initialising Models\n",
      "2025-11-02 21:21:28,141 :: root :: INFO :: Initialising Datasets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import timm\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "\n",
    "\n",
    "from pytorch_tcn import TCN\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"..\")))\n",
    "\n",
    "\n",
    "from src.utils.k_folds_creator import KFoldCreator\n",
    "from src.utils.utils import get_models_save_path\n",
    "from src.utils.constants import Constants\n",
    "from src.utils.feature_extraction import FeatureExtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a6f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ClassifierHead(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x); x = self.bn1(x); x = self.relu(x)\n",
    "        x = self.dropout(x); x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class FeatureDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    def __len__(self): return len(self.features)\n",
    "    def __getitem__(self, idx): return self.features[idx], self.labels[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb12e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CFG:\n",
    "    # Fold Config\n",
    "    SEED = 42\n",
    "    N_SPLITS = 5\n",
    "    \n",
    "    # Paths \n",
    "    DATA_PATH = '../../../data/'\n",
    "    TRAIN_CSV_NAME = 'processed_data_sum_votes_window.csv'\n",
    "    DATA_PREP_VOTE_METHOD = \"sum_and_normalize\" \n",
    "    FEATURE_STORE_PATH = DATA_PATH + 'extracted_feature/'\n",
    "    \n",
    "    # TCN Config \n",
    "    TCN_MODEL_DIR = \"TCNModel\"\n",
    "    TCN_NUM_CHANNELS = 20\n",
    "    TCN_CHANNEL_SIZES = [64, 128, 128, 256, 256, 512, 512, 512]\n",
    "    TCN_KERNEL_SIZE = 21\n",
    "    TCN_DROPOUT = 0.35\n",
    "    TCN_DOWNSAMPLE_FACTOR = 3\n",
    "\n",
    "    # CNN Config\n",
    "    CNN_MODEL_DIR = \"MultiSpectCNN\"\n",
    "    CNN_MODEL_NAME = 'tf_efficientnet_b0_ns'\n",
    "    CNN_IN_CHANNELS = 8\n",
    "    CNN_IMG_SIZE = (128, 256)\n",
    "    CNN_EEG_SPEC_PATH = '../../../data/custom_eegs/cwt'\n",
    "    \n",
    "    # Feature Head Config \n",
    "    HEAD_MODEL_SAVE_DIR = get_models_save_path() / \"MultiModalHead\" / DATA_PREP_VOTE_METHOD\n",
    "    HEAD_HIDDEN_SIZE = 512\n",
    "    HEAD_DROPOUT = 0.4\n",
    "    HEAD_BATCH_SIZE = 64\n",
    "    HEAD_EPOCHS = 20\n",
    "    HEAD_LR = 1e-4\n",
    "    TARGET_SIZE = 6\n",
    "\n",
    "    # General Inference\n",
    "    INFERENCE_BATCH_SIZE = 64\n",
    "    NUM_WORKERS = 0 \n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "set_seed(CFG.SEED)\n",
    "CFG.HEAD_MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8aaaff",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f1922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing Fold 0\n",
      "==================================================\n",
      "Cached features not found. Generating for Fold 0...\n",
      "Loading TCN Model for Fold 0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4584b7b0ea4412b079f1e22216d0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Features:   0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_head_training(train_loader, valid_loader, input_size, fold_k):\n",
    "    \"\"\"Trains the classifier head for one fold.\"\"\"\n",
    "    model = ClassifierHead(\n",
    "        input_size=input_size,\n",
    "        hidden_size=CFG.HEAD_HIDDEN_SIZE,\n",
    "        output_size=CFG.TARGET_SIZE,\n",
    "        dropout=CFG.HEAD_DROPOUT\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.HEAD_LR)\n",
    "    loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(CFG.HEAD_EPOCHS):\n",
    "        model.train()\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            log_probs = F.log_softmax(outputs, dim=1)\n",
    "            loss = loss_fn(log_probs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for features, labels in valid_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                outputs = model(features)\n",
    "                log_probs = F.log_softmax(outputs, dim=1)\n",
    "                loss = loss_fn(log_probs, labels)\n",
    "                valid_loss += loss.item() * features.size(0)\n",
    "        \n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        \n",
    "        if valid_loss < best_val_loss:\n",
    "            best_val_loss = valid_loss\n",
    "            save_path = CFG.HEAD_MODEL_SAVE_DIR / f'best_head_fold{fold_k}.pth'\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            \n",
    "        print(f\"  Epoch {epoch+1}/{CFG.HEAD_EPOCHS}, Val Loss: {valid_loss:.4f}\")\n",
    "\n",
    "    print(f\"  Fold {fold_k} Best Val Loss: {best_val_loss:.4f}\")\n",
    "    return best_val_loss\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    CFG.FEATURE_CACHE_PATH = Path(CFG.FEATURE_STORE_PATH) \n",
    "    Path(CFG.FEATURE_CACHE_PATH).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    df_path = Path(CFG.DATA_PATH) / CFG.TRAIN_CSV_NAME\n",
    "    df = pd.read_csv(df_path)\n",
    "    \n",
    "    fold_creator = KFoldCreator(n_splits=CFG.N_SPLITS, seed=CFG.SEED)\n",
    "    df = fold_creator.create_folds(df, stratify_col='expert_consensus', group_col='patient_id')\n",
    "\n",
    "    extractor = FeatureExtraction(CFG, device)\n",
    "\n",
    "    eeg_loader_all = extractor.get_eeg_inference_loader(\n",
    "        df, CFG.DATA_PATH, CFG.TCN_DOWNSAMPLE_FACTOR\n",
    "    )\n",
    "    spec_loader_all = extractor.get_spec_inference_loader(\n",
    "        df, Constants.TARGETS, CFG.DATA_PATH, CFG.CNN_IMG_SIZE, CFG.CNN_EEG_SPEC_PATH\n",
    "    )\n",
    "\n",
    "    all_fold_scores = []\n",
    "\n",
    "    for fold_k in range(CFG.N_SPLITS):\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Processing Fold {fold_k}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        cache_dir = Path(CFG.FEATURE_CACHE_PATH)\n",
    "        tcn_cache_file = cache_dir / f\"tcn_features_fold{fold_k}.npy\"\n",
    "        cnn_cache_file = cache_dir / f\"cnn_features_fold{fold_k}.npy\"\n",
    "        labels_cache_file = cache_dir / f\"labels_fold{fold_k}.npy\" \n",
    "\n",
    "        if (tcn_cache_file.exists() and \n",
    "            cnn_cache_file.exists() and \n",
    "            labels_cache_file.exists()):\n",
    "            \n",
    "            print(f\"Loading features for Fold {fold_k}...\")\n",
    "            tcn_features_all = np.load(tcn_cache_file)\n",
    "            cnn_features_all = np.load(cnn_cache_file)\n",
    "            tcn_labels_all = np.load(labels_cache_file)\n",
    "            cnn_labels_all = tcn_labels_all \n",
    "\n",
    "        else:\n",
    "            print(f\"Cached features not found. Generating for Fold {fold_k}...\")\n",
    "            \n",
    "            print(f\"Loading TCN Model for Fold {fold_k}...\")\n",
    "            tcn_model_path = (\n",
    "                get_models_save_path() / CFG.TCN_MODEL_DIR / \n",
    "                CFG.DATA_PREP_VOTE_METHOD / f'best_model_fold{fold_k}.pth'\n",
    "            )\n",
    "            tcn_extractor = extractor.build_tcn_feature_extractor(tcn_model_path)\n",
    "            tcn_features_all, tcn_labels_all = extractor.extract_features(tcn_extractor, eeg_loader_all)\n",
    "            del tcn_extractor; torch.cuda.empty_cache() \n",
    "\n",
    "            print(f\"Loading CNN Model for Fold {fold_k}...\")\n",
    "            cnn_model_path = (\n",
    "                get_models_save_path() / CFG.CNN_MODEL_DIR / \n",
    "                CFG.DATA_PREP_VOTE_METHOD / f'best_model_fold{fold_k}.pth'\n",
    "            )\n",
    "            cnn_extractor = extractor.build_cnn_feature_extractor(cnn_model_path)\n",
    "            cnn_features_all, cnn_labels_all = extractor.extract_features(cnn_extractor, spec_loader_all)\n",
    "            del cnn_extractor; torch.cuda.empty_cache() \n",
    "            \n",
    "            print(f\"Saving features to cache: {cache_dir}\")\n",
    "            np.save(tcn_cache_file, tcn_features_all)\n",
    "            np.save(cnn_cache_file, cnn_features_all)\n",
    "            np.save(labels_cache_file, tcn_labels_all) \n",
    "\n",
    "        print(f\"TCN Features Extracted. Shape: {tcn_features_all.shape}\")\n",
    "        print(f\"CNN Features Extracted. Shape: {cnn_features_all.shape}\")\n",
    "        \n",
    "        if not np.array_equal(tcn_labels_all, cnn_labels_all):\n",
    "            raise ValueError(f\"Label mismatch in Fold {fold_k}!\")\n",
    "        \n",
    "        combined_features_all = np.concatenate([tcn_features_all, cnn_features_all], axis=1)\n",
    "        labels_all = tcn_labels_all\n",
    "        input_size = combined_features_all.shape[1]\n",
    "        \n",
    "        print(\"Splitting features into train/validation for this fold...\")\n",
    "        train_indices = df[df['fold'] != fold_k].index\n",
    "        val_indices = df[df['fold'] == fold_k].index\n",
    "        \n",
    "        train_features = combined_features_all[train_indices]\n",
    "        train_labels = labels_all[train_indices]\n",
    "        val_features = combined_features_all[val_indices]\n",
    "        val_labels = labels_all[val_indices]\n",
    "        \n",
    "        train_dataset = FeatureDataset(train_features, train_labels)\n",
    "        valid_dataset = FeatureDataset(val_features, val_labels)\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=CFG.HEAD_BATCH_SIZE, shuffle=True\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset, batch_size=CFG.HEAD_BATCH_SIZE, shuffle=False\n",
    "        )\n",
    "        \n",
    "        print(f\"Training classifier head for Fold {fold_k}...\")\n",
    "        best_fold_loss = run_head_training(\n",
    "            train_loader, valid_loader, input_size, fold_k\n",
    "        )\n",
    "        all_fold_scores.append(best_fold_loss)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Full 5-Fold Cross-Validation Complete.\")\n",
    "    print(f\"Scores per fold: {all_fold_scores}\")\n",
    "    \n",
    "    mean_cv_score = np.mean(all_fold_scores)\n",
    "    print(f\"\\nMean CV Score: {mean_cv_score:.4f}\")\n",
    "    print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
