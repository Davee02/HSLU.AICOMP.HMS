{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad5c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PREPARATION_VOTE_METHOD = \"max_vote_window\" # \"max_vote_window\" or \"sum_and_normalize\". Decides how to aggregate the predictions of the overlapping windows\n",
    "PRETRAINED_MODEL_NAME_OR_PATH = \"inception_v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e1b745f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/miniconda3/envs/aicomp/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/david/miniconda3/envs/aicomp/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "2025-12-03 16:57:28,612 :: root :: INFO :: Initialising Utils\n",
      "2025-12-03 16:57:29,126 :: root :: INFO :: Initialising Models\n",
      "2025-12-03 16:57:30,447 :: root :: INFO :: Initialising Datasets\n",
      "2025-12-03 16:57:30,607 :: root :: INFO :: Initialising Transformations\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm \n",
    "import wandb\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "\n",
    "if bool(os.environ.get(\"KAGGLE_URL_BASE\", \"\")):\n",
    "  import sys\n",
    "  # running on kaggle\n",
    "  sys.path.insert(0, \"/kaggle/input/hsm-source-files\")\n",
    "else:\n",
    "  # running locally\n",
    "  sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"..\")))\n",
    "\n",
    "from src.datasets.multi_spectrogram import MultiSpectrogramDataset\n",
    "from src.utils.k_folds_creator import KFoldCreator\n",
    "from src.utils.utils import get_models_save_path, set_seeds, get_raw_data_dir, get_processed_data_dir\n",
    "from src.models.base_cnn import BaseCNN\n",
    "from src.utils.constants import Constants \n",
    "from src.datasets.eeg_processor import EEGDataProcessor\n",
    "from src.transforms.mixup import MixUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2069d2a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidhodel\u001b[0m (\u001b[33mhms-hslu-aicomp-hs25\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59de120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 42\n",
    "    n_splits = 5\n",
    "    data_path = get_raw_data_dir()\n",
    "    train_eeg_spec_path = get_processed_data_dir() / \"eeg_spectrograms\" / \"train\" / \"cwt\"\n",
    "    \n",
    "    model_name = PRETRAINED_MODEL_NAME_OR_PATH\n",
    "    target_size = 6 \n",
    "    image_alignment = \"stacked\" # \"stacked\" or \"paired\"\n",
    "    \n",
    "    batch_size = 32\n",
    "    num_workers = 8\n",
    "    \n",
    "    # Stage-specific settings\n",
    "    stage1_epochs = 5\n",
    "    stage1_lr = 1e-3\n",
    "    \n",
    "    stage2_epochs = 3\n",
    "    stage2_lr = 5e-4\n",
    "    \n",
    "    patience = 5\n",
    "    min_delta = 0.001\n",
    "    \n",
    "    dropout_p = 0.1\n",
    "    \n",
    "    img_size = (128, 256)\n",
    "    # augmentations = [\"gaussian_noise\", \"time_reversal\", \"time_masking\", \"frequency_masking\"]\n",
    "    augmentations = []\n",
    "    mixup_alpha = 0.5\n",
    "    mixup_prob = 1.0\n",
    "\n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd182e4d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor initialized.\n",
      "Raw data path: '/home/david/git/aicomp/data'\n",
      "Processed data path: '/home/david/git/aicomp/data/processed'\n"
     ]
    }
   ],
   "source": [
    "TARGETS = Constants.TARGETS\n",
    "\n",
    "processor = EEGDataProcessor(raw_data_path=CFG.data_path, processed_data_path=get_processed_data_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd91183c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(train_df, valid_df):\n",
    "    \"\"\"\n",
    "    Updated to handle empty DataFrames safely.\n",
    "    Returns None for the loader if the input DataFrame is empty.\n",
    "    \"\"\"\n",
    "    train_loader = None\n",
    "    valid_loader = None\n",
    "    \n",
    "    if train_df is not None and not train_df.empty:\n",
    "        train_dataset = MultiSpectrogramDataset(\n",
    "            train_df, TARGETS, CFG.data_path, CFG.img_size, CFG.train_eeg_spec_path, mode='train', apply_augmentations=CFG.augmentations\n",
    "        )\n",
    "\n",
    "        # Create custom collate function for training if MixUp is enabled\n",
    "        train_collate_fn = MixUp(alpha=CFG.mixup_alpha, prob=CFG.mixup_prob) if CFG.mixup_prob > 0.0 else None\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=CFG.num_workers,\n",
    "            pin_memory=False,\n",
    "            drop_last=True,\n",
    "            persistent_workers=True,\n",
    "            collate_fn=train_collate_fn\n",
    "        )\n",
    "    \n",
    "    if valid_df is not None and not valid_df.empty:\n",
    "        valid_dataset = MultiSpectrogramDataset(\n",
    "            valid_df, TARGETS, CFG.data_path, CFG.img_size, CFG.train_eeg_spec_path, mode='train', apply_augmentations=[]\n",
    "        )\n",
    "        \n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=CFG.num_workers,\n",
    "            pin_memory=False,\n",
    "            drop_last=False,\n",
    "            persistent_workers=True\n",
    "        )\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ba7f18",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_one_stage(fold, stage_name, train_df, valid_df, group_name, data_preparation_vote_method, starting_checkpoint=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
    "    \n",
    "    if stage_name == \"stage1\":\n",
    "        lr = CFG.stage1_lr\n",
    "        epochs = CFG.stage1_epochs\n",
    "    else:\n",
    "        lr = CFG.stage2_lr\n",
    "        epochs = CFG.stage2_epochs\n",
    "    \n",
    "    print(f\"\\n--- Starting {stage_name} | Fold {fold} ---\")\n",
    "    \n",
    "    experiment_name = f\"{group_name}_{stage_name}_fold{fold}\"\n",
    "    \n",
    "    config = {\n",
    "        # Model\n",
    "        \"architecture\": CFG.model_name,\n",
    "        \"pretrained\": True,\n",
    "        \"image_alignment\": CFG.image_alignment,\n",
    "        # Data\n",
    "        \"fold\": fold,\n",
    "        \"stage\": stage_name,\n",
    "        \"features\": \"multi_spectrograms\",\n",
    "        \"window_selection\": data_preparation_vote_method,\n",
    "        \"augmentations\": CFG.augmentations,\n",
    "        \"mixup_alpha\": CFG.mixup_alpha,\n",
    "        \"mixup_prob\": CFG.mixup_prob,\n",
    "        # Training\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"learning_rate\": lr,\n",
    "        \"batch_size\": CFG.batch_size,\n",
    "        \"epochs\": epochs,\n",
    "        \"seed\": CFG.seed,\n",
    "        \"scheduler\": \"CosineAnnealingLR\",\n",
    "        \"dropout_p\": CFG.dropout_p,\n",
    "    }\n",
    "\n",
    "    wandb_run = wandb.init(\n",
    "        project=\"hms-aicomp-cnn-multispec\",\n",
    "        name=experiment_name,\n",
    "        group=group_name,\n",
    "        job_type=stage_name,\n",
    "        tags=['two-stage', stage_name, f'fold{fold}'],\n",
    "        config=config,\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "    model = BaseCNN(CFG.model_name, pretrained=True, num_classes=CFG.target_size, dropout_p=CFG.dropout_p, image_alignment=CFG.image_alignment)\n",
    "    model.to(device)\n",
    "    \n",
    "    if starting_checkpoint:\n",
    "        print(f\"Loading weights from {starting_checkpoint}...\")\n",
    "        model.load_state_dict(torch.load(starting_checkpoint))\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "    \n",
    "    train_loader, valid_loader = get_dataloaders(train_df, valid_df)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = get_models_save_path() / \"multi_spec_cnn_two_stage\" / CFG.model_name / data_preparation_vote_method / f'{stage_name}_fold{fold}.pth'\n",
    "    best_model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"  --- Epoch {epoch+1}/{epochs} ---\")\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"{stage_name} Training E{epoch+1}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with autocast(device_type=device.type, dtype=torch.float16):\n",
    "                outputs = model(images)\n",
    "                log_probs = F.log_softmax(outputs, dim=1)\n",
    "                loss = loss_fn(log_probs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "            wandb.log({\"train/loss\": loss.item()})\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(valid_loader, desc=f\"{stage_name} Validation\"):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                with autocast(device_type=device.type, dtype=torch.float16):\n",
    "                    outputs = model(images)\n",
    "                    log_probs = F.log_softmax(outputs, dim=1)\n",
    "                    loss = loss_fn(log_probs, labels)\n",
    "\n",
    "                valid_loss += loss.item() * images.size(0)\n",
    "\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        \n",
    "        epoch_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"   Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Valid Loss = {valid_loss:.4f}, LR = {epoch_lr:.6f}\")\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train/epoch_loss\": train_loss,\n",
    "            \"val/loss\": valid_loss,\n",
    "            \"val/kl_div\": valid_loss,\n",
    "            \"train/epoch_lr\": epoch_lr\n",
    "        })\n",
    "\n",
    "        if valid_loss < best_val_loss - CFG.min_delta:\n",
    "            best_val_loss = valid_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"  New best model saved with validation loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= CFG.patience:\n",
    "            print(f\"  Early stopping at epoch {epoch+1}\")\n",
    "            \n",
    "        scheduler.step()\n",
    "\n",
    "    return best_model_path, best_val_loss, wandb_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d9c86d5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_two_stage_training(df, data_preparation_vote_method):\n",
    "    print(\"Total Votes Distribution (Head):\")\n",
    "    print(df['total_votes'].head())\n",
    "    \n",
    "    mask_low_votes = df['total_votes'] < 10\n",
    "    mask_high_votes = df['total_votes'] >= 10\n",
    "    \n",
    "    print(f\"Stage 1 Data (Low Votes < 10): {mask_low_votes.sum()} samples\")\n",
    "    print(f\"Stage 2 Data (High Votes >= 10): {mask_high_votes.sum()} samples\")\n",
    "    \n",
    "    group_name = f\"twostage_{CFG.model_name}_multispec_dropout_{CFG.dropout_p}_mixup_alpha_{CFG.mixup_alpha}\"\n",
    "    \n",
    "    all_oof_preds = []\n",
    "    all_oof_labels = []\n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"\\n{'='*20} Processing FOLD {fold} {'='*20}\")\n",
    "        \n",
    "        valid_idx = df['fold'] == fold\n",
    "        valid_df = df[valid_idx].reset_index(drop=True)\n",
    "        \n",
    "        valid_stage2_df = valid_df[valid_df['total_votes'] >= 10].reset_index(drop=True)\n",
    "\n",
    "        # Stage 1: Train on low-vote data\n",
    "        train_stage1 = df[(df['fold'] != fold) & mask_low_votes].reset_index(drop=True)\n",
    "        \n",
    "        stage1_path, _, _ = train_one_stage(\n",
    "            fold=fold,\n",
    "            stage_name=\"stage1\",\n",
    "            train_df=train_stage1,\n",
    "            valid_df=valid_df,\n",
    "            group_name=group_name,\n",
    "            data_preparation_vote_method=data_preparation_vote_method\n",
    "        )\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "        # Stage 2: Train on high-vote data, starting from Stage 1 checkpoint\n",
    "        train_stage2 = df[(df['fold'] != fold) & mask_high_votes].reset_index(drop=True)\n",
    "        \n",
    "        stage2_path, best_val_loss, wandb_stage2_run = train_one_stage(\n",
    "            fold=fold,\n",
    "            stage_name=\"stage2\",\n",
    "            train_df=train_stage2,\n",
    "            valid_df=valid_stage2_df,\n",
    "            starting_checkpoint=stage1_path,\n",
    "            group_name=group_name,\n",
    "            data_preparation_vote_method=data_preparation_vote_method\n",
    "        )\n",
    "        \n",
    "        fold_scores.append(best_val_loss)\n",
    "\n",
    "        # Generate OOF predictions using Stage 2 model\n",
    "        print(f\"   --- Generating OOF predictions for fold {fold} ---\")\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        model = BaseCNN(CFG.model_name, pretrained=True, num_classes=CFG.target_size, dropout_p=CFG.dropout_p, image_alignment=CFG.image_alignment)\n",
    "        model.load_state_dict(torch.load(stage2_path))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        fold_oof_preds = []\n",
    "        fold_oof_labels = []\n",
    "        \n",
    "        # Use full validation set for OOF predictions\n",
    "        _, valid_loader = get_dataloaders(pd.DataFrame(), valid_df)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(valid_loader, desc=f\"OOF Prediction Fold {fold}\"):\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                probs = F.softmax(outputs, dim=1).cpu()\n",
    "\n",
    "                fold_oof_preds.append(probs)\n",
    "                fold_oof_labels.append(labels.cpu())\n",
    "\n",
    "        all_oof_preds.append(torch.cat(fold_oof_preds).numpy())\n",
    "        all_oof_labels.append(torch.cat(fold_oof_labels).numpy())\n",
    "        print(f\"   Finished OOF predictions for fold {fold}\")\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Upload artifact\n",
    "        artifact = wandb.Artifact(wandb_stage2_run.name, type='model')\n",
    "        artifact.add_file(stage2_path)\n",
    "        wandb.log_artifact(artifact)\n",
    "        wandb.finish()\n",
    "\n",
    "    if all_oof_preds and all_oof_labels:\n",
    "        print(\"\\nCalculating final OOF score...\")\n",
    "        final_oof_preds = np.concatenate(all_oof_preds)\n",
    "        final_oof_labels = np.concatenate(all_oof_labels)\n",
    "\n",
    "        oof_preds_tensor = torch.tensor(final_oof_preds, dtype=torch.float32)\n",
    "        oof_labels_tensor = torch.tensor(final_oof_labels, dtype=torch.float32)\n",
    "\n",
    "        log_oof_preds_tensor = torch.log(oof_preds_tensor)\n",
    "\n",
    "        kl_loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "        overall_oof_score = kl_loss_fn(log_oof_preds_tensor, oof_labels_tensor).item()\n",
    "\n",
    "        print(f\"\\nOverall OOF KL Score: {overall_oof_score:.4f}\")\n",
    "        print(f\"Average Fold Score: {np.mean(fold_scores):.4f}\")\n",
    "    else:\n",
    "        print(\"\\nCould not calculate OOF score because no predictions were generated.\")\n",
    "        overall_oof_score = None\n",
    "        \n",
    "    return overall_oof_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf35513",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4163262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data and creating folds...\n",
      "==================================================\n",
      "Starting EEG Data Processing Pipeline\n",
      "==================================================\n",
      "Skipping Parquet file creation as requested.\n",
      "Using 'max_vote_window' vote aggregation strategy.\n",
      "\n",
      "Processed train data saved to '/home/david/git/aicomp/data/processed/train_processed.csv'.\n",
      "Shape of the final dataframe: (17089, 13)\n",
      "\n",
      "Pipeline finished successfully!\n",
      "==================================================\n",
      "Train shape: (17089, 13)\n",
      "Targets ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
      "Folds created. Value counts per fold:\n",
      "fold\n",
      "0    4067\n",
      "1    3658\n",
      "2    3381\n",
      "4    3358\n",
      "3    2625\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data and creating folds...\")\n",
    "train_df = processor.process_data(vote_method=DATA_PREPARATION_VOTE_METHOD, skip_parquet=True)\n",
    "print('Train shape:', train_df.shape)\n",
    "print('Targets', list(TARGETS))\n",
    "\n",
    "fold_creator = KFoldCreator(n_splits=CFG.n_splits, seed=CFG.seed)\n",
    "train_df = fold_creator.create_folds(train_df, stratify_col='expert_consensus', group_col='patient_id')\n",
    "\n",
    "print(\"Folds created. Value counts per fold:\")\n",
    "print(train_df['fold'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18801280",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_oof_score = run_two_stage_training(train_df, DATA_PREPARATION_VOTE_METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b24bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Overall OOF KL Score from training: {overall_oof_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "aicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
