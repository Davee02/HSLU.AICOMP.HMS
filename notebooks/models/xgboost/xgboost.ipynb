{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PREPARATION_VOTE_METHOD = \"sum_and_normalize\" # \"max_vote_window\" or \"sum_and_normalize\". Decides how to aggregate the predictions of the overlapping windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-08 19:43:41,132 :: root :: INFO :: Initialising Utils\n",
      "2025-10-08 19:43:41,134 :: root :: INFO :: Initialising Datasets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import gc\n",
    "import pathlib\n",
    "\n",
    "if bool(os.environ.get(\"KAGGLE_URL_BASE\", \"\")):\n",
    "  import sys\n",
    "  # running on kaggle\n",
    "  sys.path.insert(0, \"/kaggle/input/hsm-source-files\")\n",
    "else:\n",
    "  # running locally\n",
    "  sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"..\")))\n",
    "\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "import torch\n",
    "\n",
    "from src.utils.utils import get_raw_data_dir, get_processed_data_dir, get_submission_csv_path, set_seeds, get_models_save_path\n",
    "from src.utils.constants import Constants\n",
    "from src.datasets.eeg_processor import EEGDataProcessor\n",
    "from src.utils.k_folds_creator import KFoldCreator\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor initialized.\n",
      "Raw data path: '/home/david/git/aicomp/data'\n",
      "Processed data path: '/home/david/git/aicomp/data/processed'\n",
      "==================================================\n",
      "Starting EEG Data Processing Pipeline\n",
      "==================================================\n",
      "Skipping NumPy file creation as requested.\n",
      "Using 'max_vote_window' vote aggregation strategy.\n",
      "\n",
      "Processed train data saved to '/home/david/git/aicomp/data/processed/train_processed.csv'.\n",
      "Shape of the final dataframe: (17089, 12)\n",
      "\n",
      "Pipeline finished successfully!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = get_raw_data_dir()\n",
    "\n",
    "processor = EEGDataProcessor(raw_data_path=DATA_PATH, processed_data_path=get_processed_data_dir())\n",
    "train_df = processor.process_data(vote_method=DATA_PREPARATION_VOTE_METHOD, skip_npy=True)\n",
    "\n",
    "test_df = pd.read_csv(DATA_PATH / \"test.csv\")\n",
    "\n",
    "kl_score = nn.KLDivLoss(reduction=\"batchmean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Spectrogram Files into Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11138 train spectrogram files to load into memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11138/11138 [05:45<00:00, 32.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded all train spectrograms into memory\n"
     ]
    }
   ],
   "source": [
    "spectrograms_dir = DATA_PATH / \"train_spectrograms\"\n",
    "spectrogram_files = list(spectrograms_dir.glob(\"*.parquet\"))\n",
    "print(f\"Found {len(spectrogram_files)} train spectrogram files to load into memory\")\n",
    "\n",
    "def get_spectrogram_content(spectrogram_file: pathlib.Path):\n",
    "  spectrogram_id = int(spectrogram_file.stem.split(\"_\")[-1])\n",
    "  content = pd.read_parquet(file)\n",
    "  content = content.drop(columns=[\"time\"]).values\n",
    "  return spectrogram_id, content\n",
    "\n",
    "spectrograms = {}\n",
    "for file in tqdm(spectrogram_files):\n",
    "  spectrogram_id, content = get_spectrogram_content(file)\n",
    "  spectrograms[spectrogram_id] = content\n",
    "\n",
    "gc.collect()\n",
    "print(\"Loaded all train spectrograms into memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We need features for the XGBoost model.\n",
    "For this, we take the mean, min and max over time for all of the 400 spectrogram frequencies (100 per chain).\n",
    "We take the middle 10 minutes of all spectrograms.\n",
    "For each EEG ID, this produces 1200 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17089/17089 [00:03<00:00, 4953.69it/s]\n"
     ]
    }
   ],
   "source": [
    "FREQUENCY_COUNT = 400 # each spectrogram has 400 frequency bins\n",
    "\n",
    "FEATURES = [f\"spec_mean_freq_{x}\" for x in range(FREQUENCY_COUNT)]\n",
    "FEATURES += [f\"spec_min_freq_{x}\" for x in range(FREQUENCY_COUNT)]\n",
    "FEATURES += [f\"spec_max_freq_{x}\" for x in range(FREQUENCY_COUNT)]\n",
    "data = np.zeros((len(train_df), len(FEATURES)))\n",
    "\n",
    "def extract_spectrogram_features(ten_minute_window):\n",
    "  average_frequencies = ten_minute_window.mean(axis=0) # average over 300 rows (10 minutes)\n",
    "  min_frequencies = ten_minute_window.min(axis=0) # min over 300 rows (10 minutes)\n",
    "  max_frequencies = ten_minute_window.max(axis=0) # max over 300 rows (10 minutes)\n",
    "  return average_frequencies, min_frequencies, max_frequencies\n",
    "\n",
    "def extract_train_spectrogram_features(row, all_spectrograms):\n",
    "  spectrogram_id = int(row[\"spectrogram_id\"])\n",
    "  middle_offset = (row[\"min_offset\"] + row[\"max_offset\"]) // 2 # this the middle between the least spectrogram offset and greatest spectogram offset\n",
    "  row_index = int(middle_offset // 2) # each spectrogram row corresponds to 2s, so we divide by 2 to get the row index\n",
    "  window = np.array(all_spectrograms[spectrogram_id][row_index:row_index+300,:])\n",
    "  average_frequencies, min_frequencies, max_frequencies = extract_spectrogram_features(window)\n",
    "  return average_frequencies, min_frequencies, max_frequencies\n",
    "\n",
    "for i in tqdm(range(len(train_df)), total=len(train_df)):\n",
    "  row = train_df.iloc[i]\n",
    "  average_features, min_features, max_frequencies = extract_train_spectrogram_features(row, spectrograms)\n",
    "\n",
    "  data[i,:FREQUENCY_COUNT] = average_features\n",
    "  data[i,FREQUENCY_COUNT:2*FREQUENCY_COUNT] = min_features\n",
    "  data[i,2*FREQUENCY_COUNT:3*FREQUENCY_COUNT] = max_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>expert_consensus</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "      <th>...</th>\n",
       "      <th>spec_max_freq_390</th>\n",
       "      <th>spec_max_freq_391</th>\n",
       "      <th>spec_max_freq_392</th>\n",
       "      <th>spec_max_freq_393</th>\n",
       "      <th>spec_max_freq_394</th>\n",
       "      <th>spec_max_freq_395</th>\n",
       "      <th>spec_max_freq_396</th>\n",
       "      <th>spec_max_freq_397</th>\n",
       "      <th>spec_max_freq_398</th>\n",
       "      <th>spec_max_freq_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>568657</td>\n",
       "      <td>789577333</td>\n",
       "      <td>20654</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>...</td>\n",
       "      <td>688.390015</td>\n",
       "      <td>658.429993</td>\n",
       "      <td>635.539978</td>\n",
       "      <td>628.020020</td>\n",
       "      <td>629.719971</td>\n",
       "      <td>626.849976</td>\n",
       "      <td>609.750000</td>\n",
       "      <td>598.270020</td>\n",
       "      <td>559.200012</td>\n",
       "      <td>547.330017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>582999</td>\n",
       "      <td>1552638400</td>\n",
       "      <td>20230</td>\n",
       "      <td>LPD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.720000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>1.410000</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642382</td>\n",
       "      <td>14960202</td>\n",
       "      <td>5955</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>35.959999</td>\n",
       "      <td>40.369999</td>\n",
       "      <td>37.049999</td>\n",
       "      <td>36.740002</td>\n",
       "      <td>38.330002</td>\n",
       "      <td>41.080002</td>\n",
       "      <td>56.959999</td>\n",
       "      <td>51.360001</td>\n",
       "      <td>40.660000</td>\n",
       "      <td>38.490002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>751790</td>\n",
       "      <td>618728447</td>\n",
       "      <td>38549</td>\n",
       "      <td>GPD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>778705</td>\n",
       "      <td>52296320</td>\n",
       "      <td>40955</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>89517.703125</td>\n",
       "      <td>86578.101562</td>\n",
       "      <td>79598.187500</td>\n",
       "      <td>70372.320312</td>\n",
       "      <td>59542.519531</td>\n",
       "      <td>48824.449219</td>\n",
       "      <td>39700.550781</td>\n",
       "      <td>32905.851562</td>\n",
       "      <td>28676.740234</td>\n",
       "      <td>27125.720703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   eeg_id  spectrogram_id  patient_id expert_consensus  seizure_vote  \\\n",
       "0  568657       789577333       20654            Other           0.0   \n",
       "1  582999      1552638400       20230              LPD           0.0   \n",
       "2  642382        14960202        5955            Other           0.0   \n",
       "3  751790       618728447       38549              GPD           0.0   \n",
       "4  778705        52296320       40955            Other           0.0   \n",
       "\n",
       "   lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote  ...  \\\n",
       "0  0.000000      0.25   0.000000   0.166667    0.583333  ...   \n",
       "1  0.857143      0.00   0.071429   0.000000    0.071429  ...   \n",
       "2  0.000000      0.00   0.000000   0.000000    1.000000  ...   \n",
       "3  0.000000      1.00   0.000000   0.000000    0.000000  ...   \n",
       "4  0.000000      0.00   0.000000   0.000000    1.000000  ...   \n",
       "\n",
       "   spec_max_freq_390  spec_max_freq_391  spec_max_freq_392  spec_max_freq_393  \\\n",
       "0         688.390015         658.429993         635.539978         628.020020   \n",
       "1           0.630000           0.890000           1.250000           1.580000   \n",
       "2          35.959999          40.369999          37.049999          36.740002   \n",
       "3           0.430000           0.320000           0.370000           0.360000   \n",
       "4       89517.703125       86578.101562       79598.187500       70372.320312   \n",
       "\n",
       "   spec_max_freq_394  spec_max_freq_395  spec_max_freq_396  spec_max_freq_397  \\\n",
       "0         629.719971         626.849976         609.750000         598.270020   \n",
       "1           1.720000           1.630000           1.410000           1.160000   \n",
       "2          38.330002          41.080002          56.959999          51.360001   \n",
       "3           0.380000           0.380000           0.370000           0.310000   \n",
       "4       59542.519531       48824.449219       39700.550781       32905.851562   \n",
       "\n",
       "   spec_max_freq_398  spec_max_freq_399  \n",
       "0         559.200012         547.330017  \n",
       "1           0.810000           0.830000  \n",
       "2          40.660000          38.490002  \n",
       "3           0.230000           0.320000  \n",
       "4       28676.740234       27125.720703  \n",
       "\n",
       "[5 rows x 1212 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "train_df[FEATURES] = data\n",
    "\n",
    "del data\n",
    "del spectrograms\n",
    "gc.collect()\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_creator = KFoldCreator(n_splits=N_SPLITS, seed=Constants.SEED)\n",
    "train_folds_df = fold_creator.create_folds(\n",
    "    df=train_df, stratify_col=\"expert_consensus\", group_col=\"patient_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "FOLD 0\n",
      "Train size: 13022, Valid size: 4067\n",
      "==============================\n",
      "[0]\teval-mlogloss:1.64093\n",
      "[25]\teval-mlogloss:1.37529\n",
      "========================================\n",
      "FOLD 1\n",
      "Train size: 13431, Valid size: 3658\n",
      "==============================\n",
      "[0]\teval-mlogloss:1.58046\n",
      "[27]\teval-mlogloss:1.13886\n",
      "========================================\n",
      "FOLD 2\n",
      "Train size: 13708, Valid size: 3381\n",
      "==============================\n",
      "[0]\teval-mlogloss:1.60073\n",
      "[35]\teval-mlogloss:1.22203\n",
      "========================================\n",
      "FOLD 3\n",
      "Train size: 14464, Valid size: 2625\n",
      "==============================\n",
      "[0]\teval-mlogloss:1.60919\n",
      "[32]\teval-mlogloss:1.28704\n",
      "========================================\n",
      "FOLD 4\n",
      "Train size: 13731, Valid size: 3358\n",
      "==============================\n",
      "[0]\teval-mlogloss:1.60742\n",
      "[25]\teval-mlogloss:1.25664\n"
     ]
    }
   ],
   "source": [
    "all_oof = []\n",
    "all_true = []\n",
    "targets_dict = {\"Seizure\":0, \"LPD\":1, \"GPD\":2, \"LRDA\":3, \"GRDA\":4, \"Other\":5}\n",
    "\n",
    "models_save_path = get_models_save_path() / \"xgboost\" / \"spectrogram_means\" / DATA_PREPARATION_VOTE_METHOD\n",
    "models_save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for fold in range(N_SPLITS):\n",
    "    fold_train_df = train_folds_df[train_folds_df[\"fold\"] != fold].reset_index(drop=True)\n",
    "    fold_valid_df = train_folds_df[train_folds_df[\"fold\"] == fold].reset_index(drop=True)\n",
    "\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"FOLD {fold}\")\n",
    "    print(f\"Train size: {len(fold_train_df)}, Valid size: {len(fold_valid_df)}\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    X_train = fold_train_df[FEATURES]\n",
    "    y_train = fold_train_df[\"expert_consensus\"].map(targets_dict)\n",
    "    \n",
    "    X_valid = fold_valid_df[FEATURES]\n",
    "    y_valid = fold_valid_df[\"expert_consensus\"].map(targets_dict)\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": len(Constants.TARGETS),\n",
    "        \"device\": \"cuda\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"seed\": Constants.SEED,\n",
    "    }\n",
    "\n",
    "    evals = [(dvalid, \"eval\")]\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=300,\n",
    "        evals=evals,\n",
    "        verbose_eval=100,\n",
    "        early_stopping_rounds=10,\n",
    "    )\n",
    "    \n",
    "    model.save_model(models_save_path / f\"fold_{fold}.json\")\n",
    "\n",
    "    oof = model.predict(dvalid)\n",
    "    all_oof.extend(oof)\n",
    "\n",
    "    all_true.extend(fold_valid_df[Constants.TARGETS].values)\n",
    "\n",
    "    del X_train, y_train, X_valid, y_valid, dtrain, dvalid, oof\n",
    "    gc.collect()\n",
    "\n",
    "all_oof = np.array(all_oof)\n",
    "all_true = np.array(all_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF KL Score: 1.0002787113189697\n"
     ]
    }
   ],
   "source": [
    "all_oof_tensor = torch.tensor(all_oof, dtype=torch.float32)\n",
    "all_true_tensor = torch.tensor(all_true, dtype=torch.float32)\n",
    "\n",
    "kl_score = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "score = kl_score(all_oof_tensor.log(), all_true_tensor).item()\n",
    "\n",
    "print(f\"OOF KL Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer on Test and create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 test spectrogram files to load into memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 32.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded all test spectrograms into memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_spectrograms_dir = DATA_PATH / \"test_spectrograms\"\n",
    "test_spectrogram_files = list(test_spectrograms_dir.glob(\"*.parquet\"))\n",
    "print(f\"Found {len(test_spectrogram_files)} test spectrogram files to load into memory\")\n",
    "\n",
    "test_spectrograms = {}\n",
    "for file in tqdm(test_spectrogram_files):\n",
    "  spectrogram_id, content = get_spectrogram_content(file)\n",
    "  test_spectrograms[spectrogram_id] = content\n",
    "\n",
    "gc.collect()\n",
    "print(\"Loaded all test spectrograms into memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1530.21it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = np.zeros((len(test_df), len(FEATURES)))\n",
    "\n",
    "def extract_test_spectrogram_features(row, all_spectrograms):\n",
    "  # this differs from train because all test spectrograms are exactly 10 minutes long, so we don't need to extract the center window\n",
    "  spectrogram_id = int(row[\"spectrogram_id\"])\n",
    "  content = np.array(all_spectrograms[spectrogram_id][:])\n",
    "  average_frequencies, min_frequencies, max_frequencies = extract_spectrogram_features(content)\n",
    "  return average_frequencies, min_frequencies, max_frequencies\n",
    "\n",
    "for i in tqdm(range(len(test_df)), total=len(test_df)):\n",
    "  row = test_df.iloc[i]\n",
    "  average_features, min_features, max_frequencies = extract_test_spectrogram_features(row, test_spectrograms)\n",
    "\n",
    "  test_data[i,:FREQUENCY_COUNT] = average_features\n",
    "  test_data[i,FREQUENCY_COUNT:2*FREQUENCY_COUNT] = min_features\n",
    "  test_data[i,2*FREQUENCY_COUNT:3*FREQUENCY_COUNT] = max_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>spec_mean_freq_0</th>\n",
       "      <th>spec_mean_freq_1</th>\n",
       "      <th>spec_mean_freq_2</th>\n",
       "      <th>spec_mean_freq_3</th>\n",
       "      <th>spec_mean_freq_4</th>\n",
       "      <th>spec_mean_freq_5</th>\n",
       "      <th>spec_mean_freq_6</th>\n",
       "      <th>...</th>\n",
       "      <th>spec_max_freq_390</th>\n",
       "      <th>spec_max_freq_391</th>\n",
       "      <th>spec_max_freq_392</th>\n",
       "      <th>spec_max_freq_393</th>\n",
       "      <th>spec_max_freq_394</th>\n",
       "      <th>spec_max_freq_395</th>\n",
       "      <th>spec_max_freq_396</th>\n",
       "      <th>spec_max_freq_397</th>\n",
       "      <th>spec_max_freq_398</th>\n",
       "      <th>spec_max_freq_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>853520</td>\n",
       "      <td>3911565283</td>\n",
       "      <td>6885</td>\n",
       "      <td>16.864132</td>\n",
       "      <td>19.120565</td>\n",
       "      <td>18.342468</td>\n",
       "      <td>13.408634</td>\n",
       "      <td>8.0575</td>\n",
       "      <td>4.890133</td>\n",
       "      <td>3.460633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   spectrogram_id      eeg_id  patient_id  spec_mean_freq_0  spec_mean_freq_1  \\\n",
       "0          853520  3911565283        6885         16.864132         19.120565   \n",
       "\n",
       "   spec_mean_freq_2  spec_mean_freq_3  spec_mean_freq_4  spec_mean_freq_5  \\\n",
       "0         18.342468         13.408634            8.0575          4.890133   \n",
       "\n",
       "   spec_mean_freq_6  ...  spec_max_freq_390  spec_max_freq_391  \\\n",
       "0          3.460633  ...               0.58               0.59   \n",
       "\n",
       "   spec_max_freq_392  spec_max_freq_393  spec_max_freq_394  spec_max_freq_395  \\\n",
       "0               0.59               0.73               0.48               0.41   \n",
       "\n",
       "   spec_max_freq_396  spec_max_freq_397  spec_max_freq_398  spec_max_freq_399  \n",
       "0                0.6                0.6               0.61                0.6  \n",
       "\n",
       "[1 rows x 1203 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[FEATURES] = test_data\n",
    "\n",
    "del test_data\n",
    "del test_spectrograms\n",
    "gc.collect()\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Predicting fold 0\n",
      "========================================\n",
      "========================================\n",
      "Predicting fold 1\n",
      "========================================\n",
      "========================================\n",
      "Predicting fold 2\n",
      "========================================\n",
      "========================================\n",
      "Predicting fold 3\n",
      "========================================\n",
      "========================================\n",
      "Predicting fold 4\n",
      "========================================\n",
      "Test predictions shape: (1, 6)\n"
     ]
    }
   ],
   "source": [
    "test_preds = []\n",
    "\n",
    "for fold in range(N_SPLITS):\n",
    "  print(\"=\" * 40)\n",
    "  print(f\"Predicting fold {fold}\")\n",
    "  print(\"=\" * 40)\n",
    "\n",
    "  X_train = test_df[FEATURES]\n",
    "  dtest = xgb.DMatrix(X_train)\n",
    "\n",
    "  model = xgb.Booster()\n",
    "  model.load_model(models_save_path / f\"fold_{fold}.json\")\n",
    "\n",
    "  preds = model.predict(dtest)\n",
    "  test_preds.append(preds)\n",
    "\n",
    "test_preds = np.mean(test_preds, axis=0)\n",
    "print(f\"Test predictions shape: {test_preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: all predictions should sum to 1\n",
    "assert np.allclose(test_preds.sum(axis=1), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"eeg_id\": test_df[\"eeg_id\"]})\n",
    "submission[Constants.TARGETS] = test_preds\n",
    "\n",
    "submission.to_csv(get_submission_csv_path(), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
